[
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "field_validator",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "field_validator",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AnyStr",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AnyStr",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "httpx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "httpx",
        "description": "httpx",
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "gnupg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gnupg",
        "description": "gnupg",
        "detail": "gnupg",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "hcl2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hcl2",
        "description": "hcl2",
        "detail": "hcl2",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "fnmatch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fnmatch",
        "description": "fnmatch",
        "detail": "fnmatch",
        "documentation": {}
    },
    {
        "label": "git",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "git",
        "description": "git",
        "detail": "git",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "src.mcp_server.main",
        "description": "src.mcp_server.main",
        "isExtraImport": true,
        "detail": "src.mcp_server.main",
        "documentation": {}
    },
    {
        "label": "CONTEXT_STORE",
        "importPath": "src.mcp_server.main",
        "description": "src.mcp_server.main",
        "isExtraImport": true,
        "detail": "src.mcp_server.main",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "src.mcp_server.main",
        "description": "src.mcp_server.main",
        "isExtraImport": true,
        "detail": "src.mcp_server.main",
        "documentation": {}
    },
    {
        "label": "call_echo_tool",
        "importPath": "src.mcp_tools.echo_tool.client",
        "description": "src.mcp_tools.echo_tool.client",
        "isExtraImport": true,
        "detail": "src.mcp_tools.echo_tool.client",
        "documentation": {}
    },
    {
        "label": "ParsedResource",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "ParsedResource",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "ParsedResource",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "DriftInfo",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "DriftType",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "AttributeDrift",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "DriftInfo",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "DriftType",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "AttributeDrift",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "ParsedResource",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "ParsedResource",
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "Recommendation",
        "importPath": "src.mcp_tools.config_optimizer.models",
        "description": "src.mcp_tools.config_optimizer.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.models",
        "documentation": {}
    },
    {
        "label": "Recommendation",
        "importPath": "src.mcp_tools.config_optimizer.models",
        "description": "src.mcp_tools.config_optimizer.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.models",
        "documentation": {}
    },
    {
        "label": "EC2InstanceTypeRule",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "OptimizerRuleConfig",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "AWSEC2Rules",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "EC2InstanceTypeRule",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "AWSS3Rules",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketEncryptionRule",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketVersioningRule",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketPublicAccessBlockRule",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "load_optimizer_rules",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_OPTIMIZER_RULES_FILENAME",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "AWSS3Rules",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketEncryptionRule",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketVersioningRule",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketPublicAccessBlockRule",
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "check_ec2_instance_optimizations",
        "importPath": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "description": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "check_s3_bucket_optimizations",
        "importPath": "src.mcp_tools.config_optimizer.aws.s3_optimizer",
        "description": "src.mcp_tools.config_optimizer.aws.s3_optimizer",
        "isExtraImport": true,
        "detail": "src.mcp_tools.config_optimizer.aws.s3_optimizer",
        "documentation": {}
    },
    {
        "label": "TerraformVariableDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformOutputDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformResourceDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformModuleCallDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformProviderDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformFileDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformModuleProcessedDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformVariableDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformOutputDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformResourceDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformModuleCallDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformProviderDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformFileDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformModuleProcessedDoc",
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "MarkdownRenderer",
        "importPath": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "description": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "documentation": {}
    },
    {
        "label": "format_value",
        "importPath": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "description": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "documentation": {}
    },
    {
        "label": "parse_hcl_file_content",
        "importPath": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "description": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "parse_terraform_module_directory",
        "importPath": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "description": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "_extract_description_from_block_body",
        "importPath": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "description": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "# Test helper if needed\r\n    _extract_string_or_first_from_list # Test helper if needed",
        "importPath": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "description": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "compare_states",
        "importPath": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "description": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "documentation": {}
    },
    {
        "label": "compare_attributes",
        "importPath": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "description": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "documentation": {}
    },
    {
        "label": "DEFAULT_IGNORED_ATTRIBUTES",
        "importPath": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "description": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "documentation": {}
    },
    {
        "label": "suggest_remediation",
        "importPath": "src.mcp_tools.iac_drift_detector.core_logic.remediation",
        "description": "src.mcp_tools.iac_drift_detector.core_logic.remediation",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.core_logic.remediation",
        "documentation": {}
    },
    {
        "label": "parse_terraform_state_file",
        "importPath": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "description": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "documentation": {}
    },
    {
        "label": "parse_terraform_plan_json_file",
        "importPath": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "description": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "isExtraImport": true,
        "detail": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "documentation": {}
    },
    {
        "label": "PolicyConfig",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "BranchNamingPolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "CommitMessagePolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "ConventionalCommitPolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "RequireIssueNumberPolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "DisallowedPatternsPolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "DisallowedPatternItem",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "FileSizePolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "load_config",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG_FILENAME",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "BranchNamingPolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "CommitMessagePolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "ConventionalCommitPolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "RequireIssueNumberPolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "DisallowedPatternsPolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "DisallowedPatternItem",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "FileSizePolicy",
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "branch",
        "importPath": "src.mcp_tools.pr_reviewer.policies",
        "description": "src.mcp_tools.pr_reviewer.policies",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.policies",
        "documentation": {}
    },
    {
        "label": "commit",
        "importPath": "src.mcp_tools.pr_reviewer.policies",
        "description": "src.mcp_tools.pr_reviewer.policies",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.policies",
        "documentation": {}
    },
    {
        "label": "file",
        "importPath": "src.mcp_tools.pr_reviewer.policies",
        "description": "src.mcp_tools.pr_reviewer.policies",
        "isExtraImport": true,
        "detail": "src.mcp_tools.pr_reviewer.policies",
        "documentation": {}
    },
    {
        "label": "CreateContextRequest",
        "kind": 6,
        "importPath": "src.mcp_server.main",
        "description": "src.mcp_server.main",
        "peekOfCode": "class CreateContextRequest(BaseModel):\n    context_id: str\n    # Add other MCP-specific fields for context creation as needed\n    # For example: metadata: Optional[Dict[str, Any]] = None\n    # initial_data: Optional[Dict[str, Any]] = None\nclass UpdateContextRequest(BaseModel):\n    # Define fields for updating a context according to MCP\n    # For example: new_data: Dict[str, Any]\n    pass\nclass GetContextResponse(BaseModel):",
        "detail": "src.mcp_server.main",
        "documentation": {}
    },
    {
        "label": "UpdateContextRequest",
        "kind": 6,
        "importPath": "src.mcp_server.main",
        "description": "src.mcp_server.main",
        "peekOfCode": "class UpdateContextRequest(BaseModel):\n    # Define fields for updating a context according to MCP\n    # For example: new_data: Dict[str, Any]\n    pass\nclass GetContextResponse(BaseModel):\n    context_id: str\n    data: Dict[str, Any]\n    # Add other MCP-specific fields\n@app.post(\"/v1/contexts\", status_code=201)\nasync def create_context(request: CreateContextRequest):",
        "detail": "src.mcp_server.main",
        "documentation": {}
    },
    {
        "label": "GetContextResponse",
        "kind": 6,
        "importPath": "src.mcp_server.main",
        "description": "src.mcp_server.main",
        "peekOfCode": "class GetContextResponse(BaseModel):\n    context_id: str\n    data: Dict[str, Any]\n    # Add other MCP-specific fields\n@app.post(\"/v1/contexts\", status_code=201)\nasync def create_context(request: CreateContextRequest):\n    \"\"\"\n    Create a new context.\n    This is a simplified placeholder. MCP might have more specific requirements.\n    \"\"\"",
        "detail": "src.mcp_server.main",
        "documentation": {}
    },
    {
        "label": "EchoPayload",
        "kind": 6,
        "importPath": "src.mcp_server.main",
        "description": "src.mcp_server.main",
        "peekOfCode": "class EchoPayload(BaseModel):\n    message: str\n    context_id: Optional[str] = None # Example: tool might operate within a context\n@app.post(\"/v1/tools/echo\")\nasync def echo_tool_endpoint(payload: EchoPayload):\n    \"\"\"\n    Echoes back the received message.\n    Optionally, this could interact with a context if context_id is provided.\n    \"\"\"\n    # For now, a simple echo.",
        "detail": "src.mcp_server.main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "src.mcp_server.main",
        "description": "src.mcp_server.main",
        "peekOfCode": "app = FastAPI(\n    title=\"Anthropic Model Context Protocol Server\",\n    description=\"A server implementing the Anthropic Model Context Protocol (MCP).\",\n    version=\"0.1.0\",\n)\n# In-memory store for contexts (for demonstration purposes)\n# In a real application, this would be a persistent database.\nCONTEXT_STORE: Dict[str, Dict[str, Any]] = {}\nclass CreateContextRequest(BaseModel):\n    context_id: str",
        "detail": "src.mcp_server.main",
        "documentation": {}
    },
    {
        "label": "check_ec2_instance_optimizations",
        "kind": 2,
        "importPath": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "description": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "peekOfCode": "def check_ec2_instance_optimizations(\n    resource: ParsedResource,\n    rules: EC2InstanceTypeRule\n) -> List[Recommendation]:\n    \"\"\"\n    Checks a parsed EC2 instance resource against configured optimization rules.\n    Args:\n        resource: The ParsedResource object representing an EC2 instance.\n        rules: The EC2InstanceTypeRule configuration.\n    Returns:",
        "detail": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "INSTANCE_FAMILY_GENERATION",
        "kind": 5,
        "importPath": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "description": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "peekOfCode": "INSTANCE_FAMILY_GENERATION = {\n    # General Purpose\n    \"t2\": {\"gen\": 2, \"family\": \"t\"}, \"t3\": {\"gen\": 3, \"family\": \"t\"}, \"t3a\": {\"gen\": 3, \"family\": \"t\"},\n    \"t4g\": {\"gen\": 4, \"family\": \"t\"},\n    \"m4\": {\"gen\": 4, \"family\": \"m\"}, \"m5\": {\"gen\": 5, \"family\": \"m\"}, \"m5a\": {\"gen\": 5, \"family\": \"m\"},\n    \"m5n\": {\"gen\": 5, \"family\": \"m\"}, \"m5zn\": {\"gen\": 5, \"family\": \"m\"},\n    \"m6i\": {\"gen\": 6, \"family\": \"m\"}, \"m6a\": {\"gen\": 6, \"family\": \"m\"}, \"m6g\": {\"gen\": 6, \"family\": \"m\"},\n    \"m7i\": {\"gen\": 7, \"family\": \"m\"}, \"m7g\": {\"gen\": 7, \"family\": \"m\"},\n    # Compute Optimized\n    \"c4\": {\"gen\": 4, \"family\": \"c\"}, \"c5\": {\"gen\": 5, \"family\": \"c\"}, \"c5a\": {\"gen\": 5, \"family\": \"c\"},",
        "detail": "src.mcp_tools.config_optimizer.aws.ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "check_s3_bucket_optimizations",
        "kind": 2,
        "importPath": "src.mcp_tools.config_optimizer.aws.s3_optimizer",
        "description": "src.mcp_tools.config_optimizer.aws.s3_optimizer",
        "peekOfCode": "def check_s3_bucket_optimizations(\n    resource: ParsedResource,\n    rules: AWSS3Rules\n) -> List[Recommendation]:\n    \"\"\"\n    Checks a parsed S3 bucket resource against configured optimization rules.\n    Args:\n        resource: The ParsedResource object representing an S3 bucket.\n        rules: The AWSS3Rules configuration object.\n    Returns:",
        "detail": "src.mcp_tools.config_optimizer.aws.s3_optimizer",
        "documentation": {}
    },
    {
        "label": "run_optimization_checks",
        "kind": 2,
        "importPath": "src.mcp_tools.config_optimizer.cli",
        "description": "src.mcp_tools.config_optimizer.cli",
        "peekOfCode": "def run_optimization_checks(\n    iac_resources: List[ParsedResource],\n    rules_config: OptimizerRuleConfig\n) -> List[Recommendation]:\n    \"\"\"\n    Runs all configured optimization checks on the provided IaC resources.\n    \"\"\"\n    all_recommendations: List[Recommendation] = []\n    print(\"\\n--- Running Configuration Optimization Checks ---\")\n    for resource in iac_resources:",
        "detail": "src.mcp_tools.config_optimizer.cli",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.mcp_tools.config_optimizer.cli",
        "description": "src.mcp_tools.config_optimizer.cli",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Configuration Optimization Recommendations Tool.\")\n    parser.add_argument(\"--iac-type\", type=str, default=\"terraform\", choices=[\"terraform\"],\n                        help=\"Type of Infrastructure as Code tool source (default: terraform).\")\n    tf_group = parser.add_argument_group('Terraform Options (if --iac-type is terraform)')\n    tf_group.add_argument(\"--tf-state-file\", type=str,\n                          help=\"Path to the Terraform state file (.tfstate) for IaC data.\")\n    parser.add_argument(\"--rules-file\", default=None,\n                        help=\"Path to the optimization rules configuration YAML file. Defaults to searching for '.config-optimizer-rules.yml'.\")\n    # parser.add_argument(\"--repo-path\", default=None, # If needed for context, not used currently",
        "detail": "src.mcp_tools.config_optimizer.cli",
        "documentation": {}
    },
    {
        "label": "EC2InstanceTypeRule",
        "kind": 6,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "class EC2InstanceTypeRule(BaseModel):\n    enabled: bool = True\n    # Example: Warn if these types are used without a 'criticality: high' tag\n    flag_large_types_without_tag: Optional[Dict[str, List[str]]] = Field(\n        default_factory=lambda: {\"criticality!\": [\"high\", \"true\"]} # tag_key!: [list_of_values_that_exempt]\n    )\n    large_instance_types_to_flag: List[str] = Field(\n        default_factory=lambda: [\"m5.24xlarge\", \"c5.18xlarge\", \"r5.24xlarge\", \"p3.16xlarge\"] # Example list\n    )\n    suggest_newer_generations: bool = True",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketEncryptionRule",
        "kind": 6,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "class S3BucketEncryptionRule(BaseModel):\n    enabled: bool = True\n    require_sse_kms: bool = False # If true, specifically look for 'aws:kms'\n    # If false, any server_side_encryption_configuration block is fine.\nclass S3BucketVersioningRule(BaseModel):\n    enabled: bool = True\n    # No specific params needed, just checks if versioning is \"Enabled\" or \"Suspended\" vs not set.\nclass S3BucketPublicAccessBlockRule(BaseModel):\n    enabled: bool = True\n    require_all_blocks_true: bool = True # Check if all four public access block settings are true",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketVersioningRule",
        "kind": 6,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "class S3BucketVersioningRule(BaseModel):\n    enabled: bool = True\n    # No specific params needed, just checks if versioning is \"Enabled\" or \"Suspended\" vs not set.\nclass S3BucketPublicAccessBlockRule(BaseModel):\n    enabled: bool = True\n    require_all_blocks_true: bool = True # Check if all four public access block settings are true\n# --- Provider-Specific Rule Groups ---\nclass AWSEC2Rules(BaseModel):\n    instance_type_optimization: EC2InstanceTypeRule = Field(default_factory=EC2InstanceTypeRule)\n    # Add other EC2 rules here, e.g., unattached_ebs, ebs_encryption",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "S3BucketPublicAccessBlockRule",
        "kind": 6,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "class S3BucketPublicAccessBlockRule(BaseModel):\n    enabled: bool = True\n    require_all_blocks_true: bool = True # Check if all four public access block settings are true\n# --- Provider-Specific Rule Groups ---\nclass AWSEC2Rules(BaseModel):\n    instance_type_optimization: EC2InstanceTypeRule = Field(default_factory=EC2InstanceTypeRule)\n    # Add other EC2 rules here, e.g., unattached_ebs, ebs_encryption\n    enabled: bool = True\nclass AWSS3Rules(BaseModel):\n    encryption: S3BucketEncryptionRule = Field(default_factory=S3BucketEncryptionRule)",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "AWSEC2Rules",
        "kind": 6,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "class AWSEC2Rules(BaseModel):\n    instance_type_optimization: EC2InstanceTypeRule = Field(default_factory=EC2InstanceTypeRule)\n    # Add other EC2 rules here, e.g., unattached_ebs, ebs_encryption\n    enabled: bool = True\nclass AWSS3Rules(BaseModel):\n    encryption: S3BucketEncryptionRule = Field(default_factory=S3BucketEncryptionRule)\n    versioning: S3BucketVersioningRule = Field(default_factory=S3BucketVersioningRule)\n    public_access_block: S3BucketPublicAccessBlockRule = Field(default_factory=S3BucketPublicAccessBlockRule)\n    # Add other S3 rules here, e.g., lifecycle_policies, storage_class analysis\n    enabled: bool = True",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "AWSS3Rules",
        "kind": 6,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "class AWSS3Rules(BaseModel):\n    encryption: S3BucketEncryptionRule = Field(default_factory=S3BucketEncryptionRule)\n    versioning: S3BucketVersioningRule = Field(default_factory=S3BucketVersioningRule)\n    public_access_block: S3BucketPublicAccessBlockRule = Field(default_factory=S3BucketPublicAccessBlockRule)\n    # Add other S3 rules here, e.g., lifecycle_policies, storage_class analysis\n    enabled: bool = True\n# --- Main Optimizer Configuration Model ---\nclass OptimizerRuleConfig(BaseModel):\n    aws_ec2: AWSEC2Rules = Field(default_factory=AWSEC2Rules)\n    aws_s3: AWSS3Rules = Field(default_factory=AWSS3Rules)",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "OptimizerRuleConfig",
        "kind": 6,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "class OptimizerRuleConfig(BaseModel):\n    aws_ec2: AWSEC2Rules = Field(default_factory=AWSEC2Rules)\n    aws_s3: AWSS3Rules = Field(default_factory=AWSS3Rules)\n    # Add other providers or global rules here\n    # e.g., global_tags_policy: Optional[SomeTagPolicy] = None\n# --- Loading Function ---\ndef load_optimizer_rules(config_path: Optional[str] = None) -> OptimizerRuleConfig:\n    \"\"\"\n    Loads optimization rules from a YAML file.\n    If config_path is None, tries to load from '.config-optimizer-rules.yml'.",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "load_optimizer_rules",
        "kind": 2,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "def load_optimizer_rules(config_path: Optional[str] = None) -> OptimizerRuleConfig:\n    \"\"\"\n    Loads optimization rules from a YAML file.\n    If config_path is None, tries to load from '.config-optimizer-rules.yml'.\n    If no file is found or path is invalid, returns default rule configuration.\n    \"\"\"\n    actual_config_path = config_path\n    if not actual_config_path:\n        # Search for default config file in current and parent directories\n        current_dir = os.getcwd()",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_OPTIMIZER_RULES_FILENAME",
        "kind": 5,
        "importPath": "src.mcp_tools.config_optimizer.config",
        "description": "src.mcp_tools.config_optimizer.config",
        "peekOfCode": "DEFAULT_OPTIMIZER_RULES_FILENAME = \".config-optimizer-rules.yml\"\n# --- Individual Rule Component Models ---\nclass EC2InstanceTypeRule(BaseModel):\n    enabled: bool = True\n    # Example: Warn if these types are used without a 'criticality: high' tag\n    flag_large_types_without_tag: Optional[Dict[str, List[str]]] = Field(\n        default_factory=lambda: {\"criticality!\": [\"high\", \"true\"]} # tag_key!: [list_of_values_that_exempt]\n    )\n    large_instance_types_to_flag: List[str] = Field(\n        default_factory=lambda: [\"m5.24xlarge\", \"c5.18xlarge\", \"r5.24xlarge\", \"p3.16xlarge\"] # Example list",
        "detail": "src.mcp_tools.config_optimizer.config",
        "documentation": {}
    },
    {
        "label": "Recommendation",
        "kind": 6,
        "importPath": "src.mcp_tools.config_optimizer.models",
        "description": "src.mcp_tools.config_optimizer.models",
        "peekOfCode": "class Recommendation(BaseModel):\n    \"\"\"Represents a single optimization recommendation.\"\"\"\n    rule_id: str  # Identifier for the rule that triggered this recommendation\n    severity: str # e.g., \"High\", \"Medium\", \"Low\", \"Informational\"\n    resource_type: str\n    resource_name: str # Logical name from IaC\n    resource_id: Optional[str] = None # Actual cloud ID, if available from parsed data\n    message: str # Human-readable description of the issue and recommendation\n    # Optional: Add fields for suggested_action_command, documentation_url, etc.\n    details: Dict[str, Any] = Field(default_factory=dict) # For any extra context",
        "detail": "src.mcp_tools.config_optimizer.models",
        "documentation": {}
    },
    {
        "label": "call_echo_tool",
        "kind": 2,
        "importPath": "src.mcp_tools.echo_tool.client",
        "description": "src.mcp_tools.echo_tool.client",
        "peekOfCode": "def call_echo_tool(\n    server_url: str,\n    message: str,\n    context_id: str = None,\n    http_client: httpx.Client = None\n) -> dict:\n    \"\"\"\n    Calls the echo tool endpoint on the MCP server.\n    Args:\n        server_url: The base URL of the MCP server.",
        "detail": "src.mcp_tools.echo_tool.client",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.mcp_tools.echo_tool.client",
        "description": "src.mcp_tools.echo_tool.client",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"MCP Echo Tool Client\")\n    parser.add_argument(\"message\", type=str, help=\"The message to send to the echo tool.\")\n    parser.add_argument(\"--server-url\", type=str, default=DEFAULT_SERVER_URL,\n                        help=f\"The base URL of the MCP server (default: {DEFAULT_SERVER_URL}).\")\n    parser.add_argument(\"--context-id\", type=str, help=\"Optional context ID to associate with the echo request.\")\n    args = parser.parse_args()\n    try:\n        result = call_echo_tool(args.server_url, args.message, args.context_id)\n        print(\"Server response:\")",
        "detail": "src.mcp_tools.echo_tool.client",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SERVER_URL",
        "kind": 5,
        "importPath": "src.mcp_tools.echo_tool.client",
        "description": "src.mcp_tools.echo_tool.client",
        "peekOfCode": "DEFAULT_SERVER_URL = \"http://localhost:8000\"\ndef call_echo_tool(\n    server_url: str,\n    message: str,\n    context_id: str = None,\n    http_client: httpx.Client = None\n) -> dict:\n    \"\"\"\n    Calls the echo tool endpoint on the MCP server.\n    Args:",
        "detail": "src.mcp_tools.echo_tool.client",
        "documentation": {}
    },
    {
        "label": "generate_gpg_key",
        "kind": 2,
        "importPath": "src.mcp_tools.gpg_github_tool.key_manager",
        "description": "src.mcp_tools.gpg_github_tool.key_manager",
        "peekOfCode": "def generate_gpg_key(gpg_home: str, name: str, email: str, expiry: str, passphrase: str = None) -> tuple[str, str, str]:\n    \"\"\"\n    Generates a new GPG key pair.\n    Args:\n        gpg_home: Path to the GPG home directory to use.\n        name: Real name for the GPG key.\n        email: Email for the GPG key.\n        expiry: Expiration date for the GPG key (e.g., 0 for no expiry, 1y, 7d).\n        passphrase: Optional passphrase for the key. If None, key will not be passphrase protected.\n    Returns:",
        "detail": "src.mcp_tools.gpg_github_tool.key_manager",
        "documentation": {}
    },
    {
        "label": "add_gpg_key_to_github",
        "kind": 2,
        "importPath": "src.mcp_tools.gpg_github_tool.key_manager",
        "description": "src.mcp_tools.gpg_github_tool.key_manager",
        "peekOfCode": "def add_gpg_key_to_github(public_key_armored: str, github_token: str) -> bool:\n    \"\"\"\n    Adds the GPG public key to the authenticated user's GitHub account.\n    Args:\n        public_key_armored: The GPG public key in ASCII-armored format.\n        github_token: GitHub Personal Access Token with 'write:gpg_key' scope.\n    Returns:\n        True if successful, False otherwise.\n    \"\"\"\n    headers = {",
        "detail": "src.mcp_tools.gpg_github_tool.key_manager",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.mcp_tools.gpg_github_tool.key_manager",
        "description": "src.mcp_tools.gpg_github_tool.key_manager",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Generate a GPG key and add it to GitHub.\")\n    parser.add_argument(\"--name\", required=True, help=\"Real name for the GPG key (e.g., 'Tyler Zervas Agent').\")\n    parser.add_argument(\"--email\", required=True, help=\"Email for the GPG key (e.g., 'tz-dev-agent@vectorwieght.com').\")\n    parser.add_argument(\"--expiry\", default=DEFAULT_KEY_EXPIRY,\n                        help=f\"Expiration for the GPG key (e.g., 0, 1y, 30d). Default: {DEFAULT_KEY_EXPIRY}.\")\n    parser.add_argument(\"--passphrase\", default=None, help=\"Optional passphrase for the GPG key. If not provided, key will have no passphrase (less secure).\")\n    parser.add_argument(\"--github-token\", help=\"GitHub Personal Access Token with 'write:gpg_key' scope. Can also be set via GITHUB_TOKEN env var.\")\n    parser.add_argument(\"--gpg-home\", default=None,\n                        help=f\"Custom GPG home directory. Default: ~/{DEFAULT_GPG_HOME_RELATIVE} (a new temporary one is used if this is not set).\")",
        "detail": "src.mcp_tools.gpg_github_tool.key_manager",
        "documentation": {}
    },
    {
        "label": "DEFAULT_GPG_HOME_RELATIVE",
        "kind": 5,
        "importPath": "src.mcp_tools.gpg_github_tool.key_manager",
        "description": "src.mcp_tools.gpg_github_tool.key_manager",
        "peekOfCode": "DEFAULT_GPG_HOME_RELATIVE = \".gnupg_mcp_tool\" # Relative to user's home directory\nDEFAULT_KEY_EXPIRY = \"7d\" # Default to 7 days for short-lived keys\nGITHUB_API_URL = \"https://api.github.com\"\ndef generate_gpg_key(gpg_home: str, name: str, email: str, expiry: str, passphrase: str = None) -> tuple[str, str, str]:\n    \"\"\"\n    Generates a new GPG key pair.\n    Args:\n        gpg_home: Path to the GPG home directory to use.\n        name: Real name for the GPG key.\n        email: Email for the GPG key.",
        "detail": "src.mcp_tools.gpg_github_tool.key_manager",
        "documentation": {}
    },
    {
        "label": "DEFAULT_KEY_EXPIRY",
        "kind": 5,
        "importPath": "src.mcp_tools.gpg_github_tool.key_manager",
        "description": "src.mcp_tools.gpg_github_tool.key_manager",
        "peekOfCode": "DEFAULT_KEY_EXPIRY = \"7d\" # Default to 7 days for short-lived keys\nGITHUB_API_URL = \"https://api.github.com\"\ndef generate_gpg_key(gpg_home: str, name: str, email: str, expiry: str, passphrase: str = None) -> tuple[str, str, str]:\n    \"\"\"\n    Generates a new GPG key pair.\n    Args:\n        gpg_home: Path to the GPG home directory to use.\n        name: Real name for the GPG key.\n        email: Email for the GPG key.\n        expiry: Expiration date for the GPG key (e.g., 0 for no expiry, 1y, 7d).",
        "detail": "src.mcp_tools.gpg_github_tool.key_manager",
        "documentation": {}
    },
    {
        "label": "GITHUB_API_URL",
        "kind": 5,
        "importPath": "src.mcp_tools.gpg_github_tool.key_manager",
        "description": "src.mcp_tools.gpg_github_tool.key_manager",
        "peekOfCode": "GITHUB_API_URL = \"https://api.github.com\"\ndef generate_gpg_key(gpg_home: str, name: str, email: str, expiry: str, passphrase: str = None) -> tuple[str, str, str]:\n    \"\"\"\n    Generates a new GPG key pair.\n    Args:\n        gpg_home: Path to the GPG home directory to use.\n        name: Real name for the GPG key.\n        email: Email for the GPG key.\n        expiry: Expiration date for the GPG key (e.g., 0 for no expiry, 1y, 7d).\n        passphrase: Optional passphrase for the key. If None, key will not be passphrase protected.",
        "detail": "src.mcp_tools.gpg_github_tool.key_manager",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_doc_generator.cli",
        "description": "src.mcp_tools.iac_doc_generator.cli",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Automated IaC Documentation Generator for Terraform Modules.\")\n    parser.add_argument(\"input_dir\", type=str,\n                        help=\"Path to the directory containing the Terraform module (.tf files).\")\n    parser.add_argument(\"--output-file\", \"-o\", type=str, default=None,\n                        help=\"Path to the output Markdown file. If not specified, prints to STDOUT. \"\n                             \"If a directory is specified, a README.md will be created in it.\")\n    # Future args:\n    # parser.add_argument(\"--recursive\", action=\"store_true\", help=\"Recursively process submodules.\")\n    # parser.add_argument(\"--format\", type=str, default=\"markdown\", choices=[\"markdown\"], help=\"Output format.\")",
        "detail": "src.mcp_tools.iac_doc_generator.cli",
        "documentation": {}
    },
    {
        "label": "MarkdownRenderer",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "description": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "peekOfCode": "class MarkdownRenderer:\n    def __init__(self, module_doc: TerraformModuleProcessedDoc):\n        self.module_doc = module_doc\n        self.lines: List[str] = []\n    def _add_line(self, text: str = \"\"):\n        self.lines.append(text)\n    def _add_header(self, level: int, text: str):\n        self.lines.append(f\"{'#' * level} {text}\")\n        self._add_line()\n    def _render_variables(self, variables: List[TerraformVariableDoc]):",
        "detail": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "documentation": {}
    },
    {
        "label": "format_value",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "description": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "peekOfCode": "def format_value(value: Any) -> str:\n    \"\"\"Helper to format default values or other complex values for display.\"\"\"\n    if isinstance(value, (str, int, float, bool)):\n        return f\"`{value}`\"\n    if value is None:\n        return \"`null`\" # or \"Not set\" or \"\"\n    # For lists or dicts, show a compact representation or placeholder\n    if isinstance(value, list):\n        if not value: return \"`[]`\"\n        return f\"`{str(value)[:50]}{'...' if len(str(value)) > 50 else ''}`\" # Truncate long lists",
        "detail": "src.mcp_tools.iac_doc_generator.markdown_renderer",
        "documentation": {}
    },
    {
        "label": "TerraformVariableDoc",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "peekOfCode": "class TerraformVariableDoc(BaseModel):\n    name: str\n    type: Optional[str] = None\n    description: Optional[str] = None\n    default: Optional[Any] = None # Can be any type\n    is_sensitive: bool = False\nclass TerraformOutputDoc(BaseModel):\n    name: str\n    description: Optional[str] = None\n    # Value is not usually documented from HCL, but sensitive status might be",
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformOutputDoc",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "peekOfCode": "class TerraformOutputDoc(BaseModel):\n    name: str\n    description: Optional[str] = None\n    # Value is not usually documented from HCL, but sensitive status might be\n    is_sensitive: bool = False\nclass TerraformResourceDoc(BaseModel):\n    resource_type: str # e.g., \"aws_instance\"\n    resource_name: str # e.g., \"my_web_server\"\n    # We might not extract all attributes, but key ones or a summary\n    # For now, just type and name. Detailed attributes can be a future enhancement.",
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformResourceDoc",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "peekOfCode": "class TerraformResourceDoc(BaseModel):\n    resource_type: str # e.g., \"aws_instance\"\n    resource_name: str # e.g., \"my_web_server\"\n    # We might not extract all attributes, but key ones or a summary\n    # For now, just type and name. Detailed attributes can be a future enhancement.\n    # attributes: Dict[str, Any] = Field(default_factory=dict)\n    source_file: str # File where this resource is defined\n    # comments: Optional[str] = None # Associated comments\nclass TerraformModuleCallDoc(BaseModel):\n    module_name: str # Logical name of the module call",
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformModuleCallDoc",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "peekOfCode": "class TerraformModuleCallDoc(BaseModel):\n    module_name: str # Logical name of the module call\n    source: str # Source path/URL of the module\n    # version: Optional[str] = None # If specified\n    # arguments: Dict[str, Any] = Field(default_factory=dict) # Key arguments passed\n    source_file: str\n    # comments: Optional[str] = None\nclass TerraformProviderDoc(BaseModel):\n    name: str # e.g., \"aws\"\n    alias: Optional[str] = None",
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformProviderDoc",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "peekOfCode": "class TerraformProviderDoc(BaseModel):\n    name: str # e.g., \"aws\"\n    alias: Optional[str] = None\n    # config: Dict[str, Any] = Field(default_factory=dict) # e.g. region, version\n    source_file: str\nclass TerraformFileDoc(BaseModel):\n    \"\"\"Represents documentation extracted from a single .tf file.\"\"\"\n    file_path: str\n    description: Optional[str] = None # Module-level or file-level comment\n    variables: List[TerraformVariableDoc] = Field(default_factory=list)",
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformFileDoc",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "peekOfCode": "class TerraformFileDoc(BaseModel):\n    \"\"\"Represents documentation extracted from a single .tf file.\"\"\"\n    file_path: str\n    description: Optional[str] = None # Module-level or file-level comment\n    variables: List[TerraformVariableDoc] = Field(default_factory=list)\n    outputs: List[TerraformOutputDoc] = Field(default_factory=list)\n    resources: List[TerraformResourceDoc] = Field(default_factory=list)\n    module_calls: List[TerraformModuleCallDoc] = Field(default_factory=list)\n    providers: List[TerraformProviderDoc] = Field(default_factory=list)\n    # data_sources: List[...] # Future",
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "TerraformModuleProcessedDoc",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_doc_generator.models",
        "description": "src.mcp_tools.iac_doc_generator.models",
        "peekOfCode": "class TerraformModuleProcessedDoc(BaseModel):\n    \"\"\"Represents combined documentation for a Terraform module (directory).\"\"\"\n    module_path: str # Directory path of the module\n    description: Optional[str] = None # Overall module description (e.g., from a main.tf comment or a dedicated doc file)\n    files: List[TerraformFileDoc] = Field(default_factory=list)\n    # Aggregated view (optional, can be generated by assembler)\n    # all_variables: List[TerraformVariableDoc] = Field(default_factory=list)\n    # all_outputs: List[TerraformOutputDoc] = Field(default_factory=list)\n    # all_resources: List[TerraformResourceDoc] = Field(default_factory=list)\n    # all_module_calls: List[TerraformModuleCallDoc] = Field(default_factory=list)",
        "detail": "src.mcp_tools.iac_doc_generator.models",
        "documentation": {}
    },
    {
        "label": "parse_hcl_file_content",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "description": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "peekOfCode": "def parse_hcl_file_content(hcl_content: str, file_path_str: str) -> TerraformFileDoc:\n    \"\"\"\n    Parses the content of a single HCL (.tf) file.\n    \"\"\"\n    file_doc = TerraformFileDoc(file_path=file_path_str)\n    try:\n        # Use hcl2.loads() for parsing a string\n        parsed_data = hcl2.loads(hcl_content) # type: ignore\n        if not parsed_data:\n            return file_doc # Empty or unparsable content",
        "detail": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "parse_terraform_module_directory",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "description": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "peekOfCode": "def parse_terraform_module_directory(module_dir_path: str) -> TerraformModuleProcessedDoc:\n    \"\"\"\n    Parses all .tf files in a given directory (Terraform module) and aggregates results.\n    \"\"\"\n    module_path_obj = Path(module_dir_path)\n    if not module_path_obj.is_dir():\n        raise ValueError(f\"Provided path is not a directory: {module_dir_path}\")\n    module_doc = TerraformModuleProcessedDoc(module_path=str(module_path_obj.resolve()))\n    # Try to find a module description (e.g. from a main.tf comment or a dedicated README in the module)\n    # This is a placeholder for more advanced description extraction.",
        "detail": "src.mcp_tools.iac_doc_generator.terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "MockActualStateConnector",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_drift_detector.connectors.mock_connector",
        "description": "src.mcp_tools.iac_drift_detector.connectors.mock_connector",
        "peekOfCode": "class MockActualStateConnector:\n    \"\"\"\n    Simulates fetching actual infrastructure state.\n    \"\"\"\n    def __init__(self, mock_data: Optional[List[Dict[str, Any]]] = None):\n        \"\"\"\n        Initializes the mock connector.\n        Args:\n            mock_data: A list of dictionaries, where each dictionary represents\n                       an actual resource's properties. If None, default mock data is used.",
        "detail": "src.mcp_tools.iac_drift_detector.connectors.mock_connector",
        "documentation": {}
    },
    {
        "label": "compare_attributes",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "description": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "peekOfCode": "def compare_attributes(\n    iac_attrs: Dict[str, Any],\n    actual_attrs: Dict[str, Any],\n    resource_type: str, # For type-specific ignore rules\n    ignored_attributes_config: Optional[Dict[str, List[str]]] = None\n) -> List[AttributeDrift]:\n    \"\"\"\n    Compares attributes of two resource states (IaC vs Actual).\n    Args:\n        iac_attrs: Attributes from the IaC definition.",
        "detail": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "documentation": {}
    },
    {
        "label": "compare_states",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "description": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "peekOfCode": "def compare_states(\n    iac_resources: List[ParsedResource],\n    actual_resources: List[ParsedResource],\n    ignored_attributes_config: Optional[Dict[str, List[str]]] = None\n) -> List[DriftInfo]:\n    \"\"\"\n    Compares the desired state (from IaC) with the actual state (from cloud).\n    Args:\n        iac_resources: List of resources defined in IaC.\n        actual_resources: List of resources found in the actual environment.",
        "detail": "src.mcp_tools.iac_drift_detector.core_logic.drift_engine",
        "documentation": {}
    },
    {
        "label": "suggest_remediation",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_drift_detector.core_logic.remediation",
        "description": "src.mcp_tools.iac_drift_detector.core_logic.remediation",
        "peekOfCode": "def suggest_remediation(drift_info: DriftInfo, iac_tool: str = \"terraform\") -> List[str]:\n    \"\"\"\n    Generates human-readable remediation suggestions for a given drift.\n    Args:\n        drift_info: A DriftInfo object describing the detected drift.\n        iac_tool: The IaC tool in use (e.g., \"terraform\", \"pulumi\"). This helps tailor\n                  suggestions to specific commands.\n    Returns:\n        A list of strings, where each string is a suggested remediation action or comment.\n    \"\"\"",
        "detail": "src.mcp_tools.iac_drift_detector.core_logic.remediation",
        "documentation": {}
    },
    {
        "label": "parse_terraform_state_file",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "description": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "peekOfCode": "def parse_terraform_state_file(file_path: str) -> List[ParsedResource]:\n    \"\"\"\n    Parses a Terraform state file (.tfstate) and extracts resources.\n    Args:\n        file_path: Path to the .tfstate file.\n    Returns:\n        A list of ParsedResource objects.\n        Returns an empty list if parsing fails or no resources are found.\n    \"\"\"\n    try:",
        "detail": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "documentation": {}
    },
    {
        "label": "parse_terraform_plan_json_file",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "description": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "peekOfCode": "def parse_terraform_plan_json_file(file_path: str) -> List[Dict[str, Any]]:\n    \"\"\"\n    Parses a Terraform plan file (JSON output from `terraform show -json <planfile>`)\n    and extracts planned changes. This is more about *changes* than current state.\n    For drift detection, we are usually more interested in the state file for \"desired state\".\n    However, a plan can show what *would* change if applied, which can indicate drift\n    if the plan is generated against an out-of-sync state.\n    This function will extract a list of resource changes for now.\n    A more sophisticated drift tool might use this to predict drift resolution.\n    Args:",
        "detail": "src.mcp_tools.iac_drift_detector.parsers.terraform_parser",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.mcp_tools.iac_drift_detector.cli",
        "description": "src.mcp_tools.iac_drift_detector.cli",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"IaC Drift Detection and Remediation Suggestion Tool.\")\n    parser.add_argument(\"--iac-type\", type=str, default=\"terraform\", choices=[\"terraform\"],\n                        help=\"Type of Infrastructure as Code tool being used (default: terraform).\")\n    # Terraform specific arguments\n    tf_group = parser.add_argument_group('Terraform Options')\n    tf_group.add_argument(\"--tf-state-file\", type=str,\n                          help=\"Path to the Terraform state file (.tfstate) for desired state.\")\n    # tf_group.add_argument(\"--tf-plan-file\", type=str, # For future use with plan-based drift\n    #                       help=\"Path to a Terraform plan JSON file (from 'terraform show -json plan.out').\")",
        "detail": "src.mcp_tools.iac_drift_detector.cli",
        "documentation": {}
    },
    {
        "label": "ParsedResource",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "peekOfCode": "class ParsedResource(BaseModel):\n    \"\"\"Standardized representation of an IaC resource or an actual cloud resource.\"\"\"\n    id: str # The primary identifier of the resource within its provider\n    type: str # e.g., \"aws_instance\", \"aws_s3_bucket\" (Terraform type or equivalent)\n    name: str # The logical name (from IaC) or a descriptive name (if actual)\n    provider_name: str # e.g., \"aws\", \"google\", \"mock\"\n    module: Optional[str] = None # Module path if from IaC\n    attributes: Dict[str, Any] = Field(default_factory=dict) # Key-value pairs of resource attributes\n    # Additional field to distinguish source, could be useful\n    # source: str # e.g., \"terraform_state\", \"actual_cloud\", \"terraform_plan\"",
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "DriftType",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "peekOfCode": "class DriftType(str, Enum):\n    MISSING_IN_ACTUAL = \"missing_in_actual\"      # Defined in IaC, not found in actual state\n    UNMANAGED_IN_ACTUAL = \"unmanaged_in_actual\"  # Found in actual state, not defined in IaC\n    MODIFIED = \"modified\"                      # Resource exists in both, but attributes differ\n    # NO_DRIFT = \"no_drift\" # Could be used for explicit non-drift reporting\nclass AttributeDrift(BaseModel):\n    attribute_name: str\n    iac_value: Any\n    actual_value: Any\nclass DriftInfo(BaseModel):",
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "AttributeDrift",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "peekOfCode": "class AttributeDrift(BaseModel):\n    attribute_name: str\n    iac_value: Any\n    actual_value: Any\nclass DriftInfo(BaseModel):\n    drift_type: DriftType\n    resource_type: str\n    resource_name: str # Logical name from IaC if available, or a descriptive name\n    resource_id: Optional[str] = None # Actual ID if available\n    iac_resource: Optional[ParsedResource] = None # The resource as defined in IaC",
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "DriftInfo",
        "kind": 6,
        "importPath": "src.mcp_tools.iac_drift_detector.models",
        "description": "src.mcp_tools.iac_drift_detector.models",
        "peekOfCode": "class DriftInfo(BaseModel):\n    drift_type: DriftType\n    resource_type: str\n    resource_name: str # Logical name from IaC if available, or a descriptive name\n    resource_id: Optional[str] = None # Actual ID if available\n    iac_resource: Optional[ParsedResource] = None # The resource as defined in IaC\n    actual_resource: Optional[ParsedResource] = None # The resource as found in actual state\n    attribute_drifts: List[AttributeDrift] = Field(default_factory=list) # For MODIFIED type\n    message: Optional[str] = None # General message about the drift\n    # Custom validator or logic could generate the message based on other fields.",
        "detail": "src.mcp_tools.iac_drift_detector.models",
        "documentation": {}
    },
    {
        "label": "check_branch_name_policy",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.policies.branch",
        "description": "src.mcp_tools.pr_reviewer.policies.branch",
        "peekOfCode": "def check_branch_name_policy(\n    branch_name: Optional[str],\n    policy: BranchNamingPolicy\n) -> List[str]:\n    \"\"\"\n    Checks if the branch name conforms to the configured pattern.\n    Args:\n        branch_name: The name of the branch to check. Can be None (e.g. detached HEAD).\n        policy: The BranchNamingPolicy configuration object.\n    Returns:",
        "detail": "src.mcp_tools.pr_reviewer.policies.branch",
        "documentation": {}
    },
    {
        "label": "check_conventional_commit_format",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.policies.commit",
        "description": "src.mcp_tools.pr_reviewer.policies.commit",
        "peekOfCode": "def check_conventional_commit_format(\n    commit_subject: str, # The first line of the commit message\n    commit_sha: str, # For context in violation messages\n    policy: ConventionalCommitPolicy\n) -> List[str]:\n    \"\"\"\n    Checks if the commit subject line adheres to Conventional Commits format.\n    Example: feat(scope)!: broadcast errors\n    Args:\n        commit_subject: The first line of the commit message.",
        "detail": "src.mcp_tools.pr_reviewer.policies.commit",
        "documentation": {}
    },
    {
        "label": "check_commit_for_issue_number",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.policies.commit",
        "description": "src.mcp_tools.pr_reviewer.policies.commit",
        "peekOfCode": "def check_commit_for_issue_number(\n    commit_message_body: str, # Full commit message body (excluding subject, or could be full message)\n    pr_title: Optional[str], # Placeholder for future use\n    pr_body: Optional[str],  # Placeholder for future use\n    commit_sha: str, # For context in violation messages\n    policy: RequireIssueNumberPolicy\n) -> List[str]:\n    \"\"\"\n    Checks if the commit message body (or future PR title/body) contains an issue number.\n    Args:",
        "detail": "src.mcp_tools.pr_reviewer.policies.commit",
        "documentation": {}
    },
    {
        "label": "check_commit_message_policies",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.policies.commit",
        "description": "src.mcp_tools.pr_reviewer.policies.commit",
        "peekOfCode": "def check_commit_message_policies(\n    commit_details: Dict, # As returned by GitUtils.get_commit_details\n    policy: CommitMessagePolicy,\n    # pr_title: Optional[str] = None, # For future PR context\n    # pr_body: Optional[str] = None   # For future PR context\n) -> List[str]:\n    \"\"\"\n    Runs all configured commit message policies for a single commit.\n    \"\"\"\n    violations: List[str] = []",
        "detail": "src.mcp_tools.pr_reviewer.policies.commit",
        "documentation": {}
    },
    {
        "label": "CONVENTIONAL_COMMIT_REGEX",
        "kind": 5,
        "importPath": "src.mcp_tools.pr_reviewer.policies.commit",
        "description": "src.mcp_tools.pr_reviewer.policies.commit",
        "peekOfCode": "CONVENTIONAL_COMMIT_REGEX = re.compile(r\"^(?P<type>[a-zA-Z_]+)(?:\\((?P<scope>[^\\)]+)\\))?(?P<breaking>!)?: (?P<subject>.+)$\")\ndef check_conventional_commit_format(\n    commit_subject: str, # The first line of the commit message\n    commit_sha: str, # For context in violation messages\n    policy: ConventionalCommitPolicy\n) -> List[str]:\n    \"\"\"\n    Checks if the commit subject line adheres to Conventional Commits format.\n    Example: feat(scope)!: broadcast errors\n    Args:",
        "detail": "src.mcp_tools.pr_reviewer.policies.commit",
        "documentation": {}
    },
    {
        "label": "check_content_disallowed_patterns",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.policies.file",
        "description": "src.mcp_tools.pr_reviewer.policies.file",
        "peekOfCode": "def check_content_disallowed_patterns(\n    filepath: str,\n    get_file_content: GetFileContentCallable, # Function to get content (e.g., from git_utils)\n    policy: DisallowedPatternsPolicy\n) -> List[str]:\n    \"\"\"\n    Checks file content for disallowed patterns.\n    Args:\n        filepath: Path of the file being checked.\n        get_file_content: A callable that takes filepath and returns its content as string or bytes.",
        "detail": "src.mcp_tools.pr_reviewer.policies.file",
        "documentation": {}
    },
    {
        "label": "check_file_size_policy",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.policies.file",
        "description": "src.mcp_tools.pr_reviewer.policies.file",
        "peekOfCode": "def check_file_size_policy(\n    filepath: str,\n    get_file_size: GetFileSizeCallable, # Function to get file size (e.g., from git_utils)\n    policy: FileSizePolicy\n) -> List[str]:\n    \"\"\"\n    Checks if the file size exceeds the configured maximum.\n    Args:\n        filepath: Path of the file being checked.\n        get_file_size: A callable that takes filepath and returns its size in bytes.",
        "detail": "src.mcp_tools.pr_reviewer.policies.file",
        "documentation": {}
    },
    {
        "label": "GetFileContentCallable",
        "kind": 5,
        "importPath": "src.mcp_tools.pr_reviewer.policies.file",
        "description": "src.mcp_tools.pr_reviewer.policies.file",
        "peekOfCode": "GetFileContentCallable = Callable[[str], Optional[AnyStr]] # Takes path, returns content or None\nGetFileSizeCallable = Callable[[str], Optional[int]] # Takes path, returns size or None\ndef check_content_disallowed_patterns(\n    filepath: str,\n    get_file_content: GetFileContentCallable, # Function to get content (e.g., from git_utils)\n    policy: DisallowedPatternsPolicy\n) -> List[str]:\n    \"\"\"\n    Checks file content for disallowed patterns.\n    Args:",
        "detail": "src.mcp_tools.pr_reviewer.policies.file",
        "documentation": {}
    },
    {
        "label": "GetFileSizeCallable",
        "kind": 5,
        "importPath": "src.mcp_tools.pr_reviewer.policies.file",
        "description": "src.mcp_tools.pr_reviewer.policies.file",
        "peekOfCode": "GetFileSizeCallable = Callable[[str], Optional[int]] # Takes path, returns size or None\ndef check_content_disallowed_patterns(\n    filepath: str,\n    get_file_content: GetFileContentCallable, # Function to get content (e.g., from git_utils)\n    policy: DisallowedPatternsPolicy\n) -> List[str]:\n    \"\"\"\n    Checks file content for disallowed patterns.\n    Args:\n        filepath: Path of the file being checked.",
        "detail": "src.mcp_tools.pr_reviewer.policies.file",
        "documentation": {}
    },
    {
        "label": "run_all_checks",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.cli",
        "description": "src.mcp_tools.pr_reviewer.cli",
        "peekOfCode": "def run_all_checks(config: PolicyConfig, git_utils: GitUtils, base_branch: str, head_branch: str) -> List[str]:\n    \"\"\"\n    Runs all configured policy checks.\n    Args:\n        config: The loaded PolicyConfig.\n        git_utils: An instance of GitUtils.\n        base_branch: The base branch for comparison (e.g., 'main').\n        head_branch: The head branch to check (e.g., current feature branch, 'HEAD').\n    Returns:\n        A list of all violation messages.",
        "detail": "src.mcp_tools.pr_reviewer.cli",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.cli",
        "description": "src.mcp_tools.pr_reviewer.cli",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"PR Policy Review Tool: Checks code changes against configured policies.\")\n    parser.add_argument(\"--base-branch\", default=\"main\",\n                        help=\"The base branch to compare against (e.g., main, develop). Default: 'main'.\")\n    parser.add_argument(\"--head-branch\", default=\"HEAD\",\n                        help=\"The head branch or revision to check (e.g., your feature branch, 'HEAD'). Default: 'HEAD'.\")\n    parser.add_argument(\"--config-file\", default=None,\n                        help=f\"Path to the policy configuration YAML file. Defaults to searching for '.pr-policy.yml'.\")\n    parser.add_argument(\"--repo-path\", default=None,\n                        help=\"Path to the Git repository. Defaults to current working directory.\")",
        "detail": "src.mcp_tools.pr_reviewer.cli",
        "documentation": {}
    },
    {
        "label": "BranchNamingPolicy",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "class BranchNamingPolicy(BaseModel):\n    pattern: Optional[str] = \"^(feature|fix|chore|docs|style|refactor|test)/[a-zA-Z0-9_.-]+$\"\n    enabled: bool = True\n    @field_validator('pattern', mode='before')\n    def compile_pattern_branch(cls, v):\n        if v is None: # Should hit default if not provided, so this might not be strictly needed unless explicitly set to None\n            # If it can be None after defaults, handle it. Pydantic v2 handles defaults before validators usually.\n            # For a default string pattern, this 'if v is None' might be less relevant.\n            # Let's assume it's possible it's passed as None in the YAML.\n            return None",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "ConventionalCommitPolicy",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "class ConventionalCommitPolicy(BaseModel):\n    enabled: bool = True\n    types: List[str] = Field(default_factory=lambda: [\"feat\", \"fix\", \"docs\", \"style\", \"refactor\", \"test\", \"chore\"])\nclass RequireIssueNumberPolicy(BaseModel):\n    pattern: Optional[str] = \"\\\\[[A-Z]+-[0-9]+\\\\]\" # Example: [PROJ-123]\n    in_commit_body: bool = True # Check commit message body\n    in_pr_title: bool = False # Placeholder for future PR title check\n    in_pr_body: bool = False  # Placeholder for future PR body check\n    enabled: bool = False\n    @field_validator('pattern', mode='before')",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "RequireIssueNumberPolicy",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "class RequireIssueNumberPolicy(BaseModel):\n    pattern: Optional[str] = \"\\\\[[A-Z]+-[0-9]+\\\\]\" # Example: [PROJ-123]\n    in_commit_body: bool = True # Check commit message body\n    in_pr_title: bool = False # Placeholder for future PR title check\n    in_pr_body: bool = False  # Placeholder for future PR body check\n    enabled: bool = False\n    @field_validator('pattern', mode='before')\n    def compile_pattern_issue(cls, v):\n        if v is None:\n            return None",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "CommitMessagePolicy",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "class CommitMessagePolicy(BaseModel):\n    conventional_commit: ConventionalCommitPolicy = Field(default_factory=ConventionalCommitPolicy)\n    require_issue_number: RequireIssueNumberPolicy = Field(default_factory=RequireIssueNumberPolicy)\n    enabled: bool = True\nclass DisallowedPatternItem(BaseModel):\n    pattern: str\n    message: Optional[str] = None\n    enabled: bool = True\n    @field_validator('pattern', mode='before')\n    def compile_pattern_disallowed(cls, v):",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "DisallowedPatternItem",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "class DisallowedPatternItem(BaseModel):\n    pattern: str\n    message: Optional[str] = None\n    enabled: bool = True\n    @field_validator('pattern', mode='before')\n    def compile_pattern_disallowed(cls, v):\n        if v is None: # Pattern is not Optional here, so this check is for robustness if data is bad\n            raise ValueError(\"Pattern for DisallowedPatternItem cannot be None\")\n        try:\n            return re.compile(v)",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "DisallowedPatternsPolicy",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "class DisallowedPatternsPolicy(BaseModel):\n    patterns: List[DisallowedPatternItem] = Field(default_factory=list)\n    enabled: bool = True\nclass FileSizePolicy(BaseModel):\n    max_bytes: int = 1048576  # 1MB\n    ignore_extensions: List[str] = Field(default_factory=list)\n    ignore_paths: List[str] = Field(default_factory=list) # Paths/patterns to ignore for file size checks\n    enabled: bool = True\n# --- Main Configuration Model ---\nclass PolicyConfig(BaseModel):",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "FileSizePolicy",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "class FileSizePolicy(BaseModel):\n    max_bytes: int = 1048576  # 1MB\n    ignore_extensions: List[str] = Field(default_factory=list)\n    ignore_paths: List[str] = Field(default_factory=list) # Paths/patterns to ignore for file size checks\n    enabled: bool = True\n# --- Main Configuration Model ---\nclass PolicyConfig(BaseModel):\n    branch_naming: BranchNamingPolicy = Field(default_factory=BranchNamingPolicy)\n    commit_messages: CommitMessagePolicy = Field(default_factory=CommitMessagePolicy)\n    disallowed_patterns: DisallowedPatternsPolicy = Field(default_factory=DisallowedPatternsPolicy)",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "PolicyConfig",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "class PolicyConfig(BaseModel):\n    branch_naming: BranchNamingPolicy = Field(default_factory=BranchNamingPolicy)\n    commit_messages: CommitMessagePolicy = Field(default_factory=CommitMessagePolicy)\n    disallowed_patterns: DisallowedPatternsPolicy = Field(default_factory=DisallowedPatternsPolicy)\n    file_size: FileSizePolicy = Field(default_factory=FileSizePolicy)\n    # Future policies can be added here\n    # documentation_changes: Optional[dict] = None\n# --- Loading Function ---\ndef load_config(config_path: Optional[str] = None) -> PolicyConfig:\n    \"\"\"",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "load_config",
        "kind": 2,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "def load_config(config_path: Optional[str] = None) -> PolicyConfig:\n    \"\"\"\n    Loads policy configuration from a YAML file.\n    If config_path is None, tries to load from '.pr-policy.yml' in the current or parent directories.\n    If no file is found, returns default configuration.\n    \"\"\"\n    if config_path:\n        if not os.path.exists(config_path):\n            raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n    else:",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG_FILENAME",
        "kind": 5,
        "importPath": "src.mcp_tools.pr_reviewer.config",
        "description": "src.mcp_tools.pr_reviewer.config",
        "peekOfCode": "DEFAULT_CONFIG_FILENAME = \".pr-policy.yml\"\n# --- Policy Specific Models ---\nclass BranchNamingPolicy(BaseModel):\n    pattern: Optional[str] = \"^(feature|fix|chore|docs|style|refactor|test)/[a-zA-Z0-9_.-]+$\"\n    enabled: bool = True\n    @field_validator('pattern', mode='before')\n    def compile_pattern_branch(cls, v):\n        if v is None: # Should hit default if not provided, so this might not be strictly needed unless explicitly set to None\n            # If it can be None after defaults, handle it. Pydantic v2 handles defaults before validators usually.\n            # For a default string pattern, this 'if v is None' might be less relevant.",
        "detail": "src.mcp_tools.pr_reviewer.config",
        "documentation": {}
    },
    {
        "label": "GitRepoError",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.git_utils",
        "description": "src.mcp_tools.pr_reviewer.git_utils",
        "peekOfCode": "class GitRepoError(Exception):\n    \"\"\"Custom exception for Git repository errors.\"\"\"\n    pass\nclass GitUtils:\n    def __init__(self, repo_path: Optional[str] = None):\n        \"\"\"\n        Initializes GitUtils.\n        Args:\n            repo_path: Path to the Git repository. Defaults to the current working directory.\n        Raises:",
        "detail": "src.mcp_tools.pr_reviewer.git_utils",
        "documentation": {}
    },
    {
        "label": "GitUtils",
        "kind": 6,
        "importPath": "src.mcp_tools.pr_reviewer.git_utils",
        "description": "src.mcp_tools.pr_reviewer.git_utils",
        "peekOfCode": "class GitUtils:\n    def __init__(self, repo_path: Optional[str] = None):\n        \"\"\"\n        Initializes GitUtils.\n        Args:\n            repo_path: Path to the Git repository. Defaults to the current working directory.\n        Raises:\n            GitRepoError: If the path is not a valid Git repository.\n        \"\"\"\n        try:",
        "detail": "src.mcp_tools.pr_reviewer.git_utils",
        "documentation": {}
    },
    {
        "label": "temp_tfstate_file_optimizer",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def temp_tfstate_file_optimizer(tmp_path: Path) -> Path:\n    file_path = tmp_path / \"test_optimizer.tfstate\"\n    with open(file_path, 'w') as f:\n        json.dump(SAMPLE_TFSTATE_CONTENT, f)\n    return file_path\n@pytest.fixture\ndef temp_optimizer_rules_file_custom(tmp_path: Path):\n    def _create_rules_file(rules_content: dict):\n        file_path = tmp_path / \"custom.rules.yml\"\n        with open(file_path, 'w') as f:",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "temp_optimizer_rules_file_custom",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def temp_optimizer_rules_file_custom(tmp_path: Path):\n    def _create_rules_file(rules_content: dict):\n        file_path = tmp_path / \"custom.rules.yml\"\n        with open(file_path, 'w') as f:\n            yaml.dump(rules_content, f)\n        return file_path\n    return _create_rules_file\ndef run_optimizer_cli(cwd_path: Path, args: list[str]) -> subprocess.CompletedProcess:\n    cmd = [\"python\", \"-m\", CLI_MODULE_PATH] + args\n    return subprocess.run(cmd, capture_output=True, text=True, cwd=cwd_path)",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "run_optimizer_cli",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def run_optimizer_cli(cwd_path: Path, args: list[str]) -> subprocess.CompletedProcess:\n    cmd = [\"python\", \"-m\", CLI_MODULE_PATH] + args\n    return subprocess.run(cmd, capture_output=True, text=True, cwd=cwd_path)\n# --- CLI Tests ---\ndef test_cli_optimizer_help_message():\n    result = subprocess.run([\"python\", \"-m\", CLI_MODULE_PATH, \"--help\"], capture_output=True, text=True)\n    assert \"usage: cli.py\" in result.stdout\n    assert \"--tf-state-file\" in result.stdout\n    assert \"--rules-file\" in result.stdout\n    assert result.returncode == 0",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_optimizer_help_message",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def test_cli_optimizer_help_message():\n    result = subprocess.run([\"python\", \"-m\", CLI_MODULE_PATH, \"--help\"], capture_output=True, text=True)\n    assert \"usage: cli.py\" in result.stdout\n    assert \"--tf-state-file\" in result.stdout\n    assert \"--rules-file\" in result.stdout\n    assert result.returncode == 0\ndef test_cli_optimizer_no_tfstate_file_error(tmp_path: Path):\n    result = run_optimizer_cli(tmp_path, [\"--iac-type\", \"terraform\"]) # Missing --tf-state-file\n    assert result.returncode != 0 # Should be 2\n    assert \"Error: For Terraform, --tf-state-file must be provided.\" in result.stderr",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_optimizer_no_tfstate_file_error",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def test_cli_optimizer_no_tfstate_file_error(tmp_path: Path):\n    result = run_optimizer_cli(tmp_path, [\"--iac-type\", \"terraform\"]) # Missing --tf-state-file\n    assert result.returncode != 0 # Should be 2\n    assert \"Error: For Terraform, --tf-state-file must be provided.\" in result.stderr\ndef test_cli_optimizer_tfstate_not_found_error(tmp_path: Path):\n    result = run_optimizer_cli(tmp_path, [\"--tf-state-file\", \"nonexistent.tfstate\"])\n    assert result.returncode != 0 # Should be 2\n    assert \"Error: Terraform state file nonexistent.tfstate not found.\" in result.stderr\ndef test_cli_optimizer_default_rules_produce_recommendations(temp_tfstate_file_optimizer: Path, tmp_path: Path):\n    \"\"\"Test with sample tfstate and default optimizer rules.\"\"\"",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_optimizer_tfstate_not_found_error",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def test_cli_optimizer_tfstate_not_found_error(tmp_path: Path):\n    result = run_optimizer_cli(tmp_path, [\"--tf-state-file\", \"nonexistent.tfstate\"])\n    assert result.returncode != 0 # Should be 2\n    assert \"Error: Terraform state file nonexistent.tfstate not found.\" in result.stderr\ndef test_cli_optimizer_default_rules_produce_recommendations(temp_tfstate_file_optimizer: Path, tmp_path: Path):\n    \"\"\"Test with sample tfstate and default optimizer rules.\"\"\"\n    tfstate_abs_path = str(temp_tfstate_file_optimizer.resolve())\n    args = [\"--tf-state-file\", tfstate_abs_path] # Uses default rules\n    result = run_optimizer_cli(tmp_path, args)\n    # print(\"STDOUT Default Rules:\", result.stdout)",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_optimizer_default_rules_produce_recommendations",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def test_cli_optimizer_default_rules_produce_recommendations(temp_tfstate_file_optimizer: Path, tmp_path: Path):\n    \"\"\"Test with sample tfstate and default optimizer rules.\"\"\"\n    tfstate_abs_path = str(temp_tfstate_file_optimizer.resolve())\n    args = [\"--tf-state-file\", tfstate_abs_path] # Uses default rules\n    result = run_optimizer_cli(tmp_path, args)\n    # print(\"STDOUT Default Rules:\", result.stdout)\n    # print(\"STDERR Default Rules:\", result.stderr)\n    assert result.returncode == 1 # Recommendations expected\n    assert \"OPTIMIZATION RECOMMENDATION(S) FOUND\" in result.stdout\n    # Check for EC2 t2.large -> newer gen (e.g. t3.large)",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_optimizer_custom_rules_file",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def test_cli_optimizer_custom_rules_file(temp_tfstate_file_optimizer: Path, temp_optimizer_rules_file_custom, tmp_path: Path):\n    custom_rules = {\n        \"aws_ec2\": {\n            \"instance_type_optimization\": {\n                \"enabled\": True,\n                \"suggest_newer_generations\": False, # Disable newer gen check\n                \"large_instance_types_to_flag\": [\"t2.large\"] # Flag t2.large as large\n            }\n        },\n        \"aws_s3\": {",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_optimizer_no_recommendations",
        "kind": 2,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "def test_cli_optimizer_no_recommendations(tmp_path: Path, temp_optimizer_rules_file_custom):\n    \"\"\"Test scenario where no recommendations are generated.\"\"\"\n    # tfstate with only the \"secure_bucket\" which should pass default-like rules\n    # if other resources that trigger recs are removed.\n    # Let's use a tfstate with only the secure_bucket\n    tfstate_secure_only = {\n        \"version\": 4, \"resources\": [SAMPLE_TFSTATE_CONTENT[\"resources\"][3]] # Only secure_bucket\n    }\n    tfstate_file = tmp_path / \"secure.tfstate\"\n    with open(tfstate_file, 'w') as f:",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "CLI_MODULE_PATH",
        "kind": 5,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "CLI_MODULE_PATH = \"src.mcp_tools.config_optimizer.cli\"\nDEFAULT_OPTIMIZER_RULES_FILENAME = \".config-optimizer-rules.yml\"\n# Sample Terraform state content for testing\nSAMPLE_TFSTATE_CONTENT = {\n    \"version\": 4, \"terraform_version\": \"1.1.0\",\n    \"resources\": [\n        { # EC2 - Old generation\n            \"mode\": \"managed\", \"type\": \"aws_instance\", \"name\": \"old_gen_ec2\",\n            \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n            \"instances\": [{\"attributes\": {\"id\": \"i-t2instance\", \"instance_type\": \"t2.large\"}}]",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "DEFAULT_OPTIMIZER_RULES_FILENAME",
        "kind": 5,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "DEFAULT_OPTIMIZER_RULES_FILENAME = \".config-optimizer-rules.yml\"\n# Sample Terraform state content for testing\nSAMPLE_TFSTATE_CONTENT = {\n    \"version\": 4, \"terraform_version\": \"1.1.0\",\n    \"resources\": [\n        { # EC2 - Old generation\n            \"mode\": \"managed\", \"type\": \"aws_instance\", \"name\": \"old_gen_ec2\",\n            \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n            \"instances\": [{\"attributes\": {\"id\": \"i-t2instance\", \"instance_type\": \"t2.large\"}}]\n        },",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "SAMPLE_TFSTATE_CONTENT",
        "kind": 5,
        "importPath": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "description": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "peekOfCode": "SAMPLE_TFSTATE_CONTENT = {\n    \"version\": 4, \"terraform_version\": \"1.1.0\",\n    \"resources\": [\n        { # EC2 - Old generation\n            \"mode\": \"managed\", \"type\": \"aws_instance\", \"name\": \"old_gen_ec2\",\n            \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n            \"instances\": [{\"attributes\": {\"id\": \"i-t2instance\", \"instance_type\": \"t2.large\"}}]\n        },\n        { # EC2 - Large type, should be flagged by default rules\n            \"mode\": \"managed\", \"type\": \"aws_instance\", \"name\": \"big_ec2\",",
        "detail": "tests.integration.test_config_optimizer.test_config_optimizer_cli",
        "documentation": {}
    },
    {
        "label": "temp_tf_module_for_cli",
        "kind": 2,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "def temp_tf_module_for_cli(tmp_path: Path) -> Path:\n    \"\"\"Fixture to create a temporary Terraform module directory with sample .tf files.\"\"\"\n    module_dir = tmp_path / \"sample_tf_module\"\n    module_dir.mkdir()\n    (module_dir / \"main.tf\").write_text(MAIN_TF_CONTENT)\n    (module_dir / \"variables.tf\").write_text(VARIABLES_TF_CONTENT)\n    (module_dir / \"outputs.tf\").write_text(OUTPUTS_TF_CONTENT)\n    # Create a dummy submodule directory as referenced by main.tf\n    # (module_dir / \"modules\" / \"custom_vpc\").mkdir(parents=True, exist_ok=True)\n    # (module_dir / \"modules\" / \"custom_vpc\" / \"main.tf\").write_text(\"# Dummy VPC module\")",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "run_iac_doc_cli",
        "kind": 2,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "def run_iac_doc_cli(cwd_path: Path, args: list[str]) -> subprocess.CompletedProcess:\n    \"\"\"Helper function to run the IaC Doc Generator CLI tool.\"\"\"\n    cmd = [\"python\", \"-m\", CLI_MODULE_PATH] + args\n    # When running module with python -m, CWD should be project root or have src in PYTHONPATH\n    # For these tests, CWD will be tmp_path where module_dir is, which might not be ideal for python -m if it can't find src.\n    # It's often better to run from project root and pass full paths to input_dir.\n    # However, subprocess.run(cwd=...) sets the CWD for the command.\n    # Let's assume tests are run from project root.\n    # If CLI needs to be run from project root:\n    # current_project_root = Path(__file__).parent.parent.parent.parent # Adjust based on actual test file depth",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_iac_doc_help_message",
        "kind": 2,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "def test_cli_iac_doc_help_message():\n    result = subprocess.run([\"python\", \"-m\", CLI_MODULE_PATH, \"--help\"], capture_output=True, text=True)\n    assert \"usage: cli.py\" in result.stdout\n    assert \"Path to the directory containing the Terraform module\" in result.stdout\n    assert \"--output-file\" in result.stdout\n    assert result.returncode == 0\ndef test_cli_iac_doc_invalid_input_dir(tmp_path: Path):\n    result = run_iac_doc_cli(tmp_path, [\"non_existent_dir\"])\n    assert result.returncode != 0\n    assert \"Error: Input path\" in result.stderr",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_iac_doc_invalid_input_dir",
        "kind": 2,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "def test_cli_iac_doc_invalid_input_dir(tmp_path: Path):\n    result = run_iac_doc_cli(tmp_path, [\"non_existent_dir\"])\n    assert result.returncode != 0\n    assert \"Error: Input path\" in result.stderr\n    assert \"is not a valid directory.\" in result.stderr\ndef test_cli_iac_doc_generate_to_stdout(temp_tf_module_for_cli: Path, tmp_path: Path):\n    input_dir_abs = str(temp_tf_module_for_cli.resolve())\n    result = run_iac_doc_cli(tmp_path, [input_dir_abs]) # Output to STDOUT by default\n    # print(\"STDOUT:\", result.stdout)\n    # print(\"STDERR:\", result.stderr)",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_iac_doc_generate_to_stdout",
        "kind": 2,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "def test_cli_iac_doc_generate_to_stdout(temp_tf_module_for_cli: Path, tmp_path: Path):\n    input_dir_abs = str(temp_tf_module_for_cli.resolve())\n    result = run_iac_doc_cli(tmp_path, [input_dir_abs]) # Output to STDOUT by default\n    # print(\"STDOUT:\", result.stdout)\n    # print(\"STDERR:\", result.stderr)\n    assert result.returncode == 0\n    assert \"--- Generated Markdown Documentation ---\" in result.stdout\n    assert \"# Terraform Module: `sample_tf_module`\" in result.stdout\n    assert \"## File: `main.tf`\" in result.stdout\n    assert \"### Providers\" in result.stdout",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_iac_doc_generate_to_output_file",
        "kind": 2,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "def test_cli_iac_doc_generate_to_output_file(temp_tf_module_for_cli: Path, tmp_path: Path):\n    input_dir_abs = str(temp_tf_module_for_cli.resolve())\n    output_file = tmp_path / \"generated_doc.md\"\n    output_file_abs = str(output_file.resolve())\n    result = run_iac_doc_cli(tmp_path, [input_dir_abs, \"--output-file\", output_file_abs])\n    # print(\"STDOUT:\", result.stdout)\n    # print(\"STDERR:\", result.stderr)\n    assert result.returncode == 0\n    assert f\"Documentation successfully written to: {output_file_abs}\" in result.stdout\n    assert output_file.exists()",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_iac_doc_generate_to_output_directory",
        "kind": 2,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "def test_cli_iac_doc_generate_to_output_directory(temp_tf_module_for_cli: Path, tmp_path: Path):\n    input_dir_abs = str(temp_tf_module_for_cli.resolve())\n    output_dir = tmp_path / \"docs_output\"\n    # CLI should create README.md inside this if it's a dir\n    # The CLI creates parent dirs for output_file, but if output_file IS a dir, it appends README.md.\n    # So, output_dir itself doesn't need to be created by this test beforehand if logic is robust.\n    # However, current CLI logic: output_path.parent.mkdir(). If output_path is a dir, parent is its parent.\n    # If output_path is docs_output/, then output_path.is_dir() is true, path becomes docs_output/README.md.\n    # Then output_path.parent (docs_output/) is created. This is fine.\n    output_dir_abs = str(output_dir.resolve())",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_iac_doc_empty_module_dir",
        "kind": 2,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "def test_cli_iac_doc_empty_module_dir(tmp_path: Path):\n    empty_module_dir = tmp_path / \"empty_tf_module\"\n    empty_module_dir.mkdir()\n    input_dir_abs = str(empty_module_dir.resolve())\n    result = run_iac_doc_cli(tmp_path, [input_dir_abs])\n    # print(\"STDOUT:\", result.stdout)\n    # print(\"STDERR:\", result.stderr)\n    assert result.returncode == 0 # Exits 0 if no .tf files found\n    assert f\"No Terraform (.tf) files found or processed in directory: {input_dir_abs}\" in result.stdout\n    assert \"--- Generated Markdown Documentation ---\" not in result.stdout # Should not attempt to print if no files",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "CLI_MODULE_PATH",
        "kind": 5,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "CLI_MODULE_PATH = \"src.mcp_tools.iac_doc_generator.cli\"\n# Sample Terraform HCL content for various files\nMAIN_TF_CONTENT = \"\"\"\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\nresource \"aws_instance\" \"web\" {\n  instance_type = \"t2.micro\"\n  ami           = \"ami-123\"\n}",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "MAIN_TF_CONTENT",
        "kind": 5,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "MAIN_TF_CONTENT = \"\"\"\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\nresource \"aws_instance\" \"web\" {\n  instance_type = \"t2.micro\"\n  ami           = \"ami-123\"\n}\nmodule \"vpc\" {\n  source = \"./modules/custom_vpc\"",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "VARIABLES_TF_CONTENT",
        "kind": 5,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "VARIABLES_TF_CONTENT = \"\"\"\nvariable \"instance_count\" {\n  description = \"Number of web instances\"\n  type        = number\n  default     = 1\n}\nvariable \"admin_user\" {\n  description = \"Admin username\"\n  type        = string\n  sensitive   = true",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "OUTPUTS_TF_CONTENT",
        "kind": 5,
        "importPath": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "description": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "peekOfCode": "OUTPUTS_TF_CONTENT = \"\"\"\noutput \"web_instance_ip\" {\n  description = \"Public IP of the web instance\"\n  value       = aws_instance.web.public_ip\n}\noutput \"vpc_id_out\" {\n  description = \"ID of the VPC\"\n  value       = module.vpc.id\n  sensitive   = true\n}",
        "detail": "tests.integration.test_iac_doc_generator.test_iac_doc_cli",
        "documentation": {}
    },
    {
        "label": "temp_tfstate_file",
        "kind": 2,
        "importPath": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "description": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "peekOfCode": "def temp_tfstate_file(tmp_path: Path) -> Path:\n    \"\"\"Fixture to create a temporary .tfstate file for testing.\"\"\"\n    file_path = tmp_path / \"test.tfstate\"\n    # Update instance_type in tfstate to ensure it's different from mock for a clear drift\n    # tfstate_content_for_test = SAMPLE_TFSTATE_CONTENT.copy()\n    # tfstate_content_for_test[\"resources\"][0][\"instances\"][0][\"attributes\"][\"instance_type\"] = \"t2.small\"\n    # No, let's rely on the tags difference from the default mock data.\n    # And the S3 ACL difference.\n    with open(file_path, 'w') as f:\n        json.dump(SAMPLE_TFSTATE_CONTENT, f)",
        "detail": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "documentation": {}
    },
    {
        "label": "run_iac_cli",
        "kind": 2,
        "importPath": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "description": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "peekOfCode": "def run_iac_cli(repo_path: Path, args: list[str]) -> subprocess.CompletedProcess:\n    \"\"\"Helper function to run the IaC Drift Detector CLI tool.\"\"\"\n    cmd = [\"python\", \"-m\", CLI_MODULE_PATH] + args\n    return subprocess.run(cmd, capture_output=True, text=True, cwd=repo_path) # Run from tmp_path itself or a sub-repo if needed\n# --- CLI Tests ---\ndef test_cli_help_message_iac():\n    \"\"\"Test if the IaC Drift CLI shows a help message.\"\"\"\n    result = subprocess.run([\"python\", \"-m\", CLI_MODULE_PATH, \"--help\"], capture_output=True, text=True)\n    assert \"usage: cli.py\" in result.stdout\n    assert \"--tf-state-file\" in result.stdout",
        "detail": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_help_message_iac",
        "kind": 2,
        "importPath": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "description": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "peekOfCode": "def test_cli_help_message_iac():\n    \"\"\"Test if the IaC Drift CLI shows a help message.\"\"\"\n    result = subprocess.run([\"python\", \"-m\", CLI_MODULE_PATH, \"--help\"], capture_output=True, text=True)\n    assert \"usage: cli.py\" in result.stdout\n    assert \"--tf-state-file\" in result.stdout\n    assert \"--actual-state-source\" in result.stdout\n    assert result.returncode == 0\ndef test_cli_no_tfstate_file_error(tmp_path: Path):\n    \"\"\"Test CLI exits with error if --tf-state-file is required but not provided or not found.\"\"\"\n    result = run_iac_cli(tmp_path, [\"--iac-type\", \"terraform\"]) # No --tf-state-file",
        "detail": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_no_tfstate_file_error",
        "kind": 2,
        "importPath": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "description": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "peekOfCode": "def test_cli_no_tfstate_file_error(tmp_path: Path):\n    \"\"\"Test CLI exits with error if --tf-state-file is required but not provided or not found.\"\"\"\n    result = run_iac_cli(tmp_path, [\"--iac-type\", \"terraform\"]) # No --tf-state-file\n    # print(\"STDOUT:\", result.stdout)\n    # print(\"STDERR:\", result.stderr)\n    assert result.returncode != 0 # Should be 2 based on cli.py\n    assert \"Error: For Terraform, either --tf-state-file must be provided.\" in result.stderr\n    result_not_found = run_iac_cli(tmp_path, [\"--iac-type\", \"terraform\", \"--tf-state-file\", \"nonexistent.tfstate\"])\n    # print(\"STDOUT:\", result_not_found.stdout)\n    # print(\"STDERR:\", result_not_found.stderr)",
        "detail": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_drift_detection_with_mock_connector",
        "kind": 2,
        "importPath": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "description": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "peekOfCode": "def test_cli_drift_detection_with_mock_connector(temp_tfstate_file: Path, tmp_path: Path):\n    \"\"\"\n    Test end-to-end drift detection using a sample tfstate and the default mock connector.\n    \"\"\"\n    tfstate_file_abs_path = str(temp_tfstate_file.resolve())\n    args = [\n        \"--iac-type\", \"terraform\",\n        \"--tf-state-file\", tfstate_file_abs_path,\n        \"--actual-state-source\", \"mock\"\n    ]",
        "detail": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_no_drift_scenario",
        "kind": 2,
        "importPath": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "description": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "peekOfCode": "def test_cli_no_drift_scenario(tmp_path: Path):\n    \"\"\"Test a scenario where desired and (mocked) actual states match.\"\"\"\n    # Create a tfstate file that perfectly matches a subset of the default mock data\n    # For simplicity, let's use only the S3 bucket part of the mock data, but make it match\n    no_drift_tfstate_content = {\n        \"version\": 4, \"resources\": [\n            {\n                \"mode\": \"managed\", \"type\": \"aws_s3_bucket\", \"name\": \"perfect_match_bucket\",\n                \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n                \"instances\": [{\"attributes\": {",
        "detail": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "documentation": {}
    },
    {
        "label": "CLI_MODULE_PATH",
        "kind": 5,
        "importPath": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "description": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "peekOfCode": "CLI_MODULE_PATH = \"src.mcp_tools.iac_drift_detector.cli\"\n# Sample Terraform state content (from terraform_parser.py's example)\n# This represents the \"desired state\"\nSAMPLE_TFSTATE_CONTENT = {\n    \"version\": 4, \"terraform_version\": \"1.0.0\", \"serial\": 1, \"lineage\": \"some-uuid\", \"outputs\": {},\n    \"resources\": [\n        { # Will match mock actual, but with different attributes -> MODIFIED\n            \"mode\": \"managed\", \"type\": \"aws_instance\", \"name\": \"example_ec2\",\n            \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n            \"instances\": [{\"schema_version\": 1, \"attributes\": {",
        "detail": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "documentation": {}
    },
    {
        "label": "SAMPLE_TFSTATE_CONTENT",
        "kind": 5,
        "importPath": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "description": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "peekOfCode": "SAMPLE_TFSTATE_CONTENT = {\n    \"version\": 4, \"terraform_version\": \"1.0.0\", \"serial\": 1, \"lineage\": \"some-uuid\", \"outputs\": {},\n    \"resources\": [\n        { # Will match mock actual, but with different attributes -> MODIFIED\n            \"mode\": \"managed\", \"type\": \"aws_instance\", \"name\": \"example_ec2\",\n            \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n            \"instances\": [{\"schema_version\": 1, \"attributes\": {\n                \"id\": \"i-12345abcdef\", \"ami\": \"ami-0c55b31ad29f52962\",\n                \"instance_type\": \"t2.micro\", \"tags\": {\"Name\": \"example-instance\"}}}]\n        },",
        "detail": "tests.integration.test_iac_drift_detector.test_iac_drift_cli",
        "documentation": {}
    },
    {
        "label": "temp_git_repo",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def temp_git_repo(tmp_path: Path):\n    \"\"\"\n    Fixture to create a temporary Git repository for testing.\n    Yields the path to the repository.\n    \"\"\"\n    repo_dir = tmp_path / \"test_repo\"\n    repo_dir.mkdir()\n    # Initialize Git repo\n    repo = git.Repo.init(repo_dir)\n    # Initial commit on main branch",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "run_cli",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def run_cli(repo_path: Path, args: list[str]) -> subprocess.CompletedProcess:\n    \"\"\"Helper function to run the CLI tool.\"\"\"\n    cmd = [\"python\", \"-m\", CLI_MODULE_PATH] + args\n    # print(f\"Running CLI: CWD={repo_path}, CMD={' '.join(cmd)}\")\n    return subprocess.run(cmd, capture_output=True, text=True, cwd=repo_path)\ndef create_policy_file(repo_path: Path, policy_content: dict):\n    \"\"\"Helper to create a .pr-policy.yml file in the repo.\"\"\"\n    with open(repo_path / DEFAULT_POLICY_FILENAME, 'w') as f:\n        yaml.dump(policy_content, f)\n# --- Basic CLI Tests ---",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "create_policy_file",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def create_policy_file(repo_path: Path, policy_content: dict):\n    \"\"\"Helper to create a .pr-policy.yml file in the repo.\"\"\"\n    with open(repo_path / DEFAULT_POLICY_FILENAME, 'w') as f:\n        yaml.dump(policy_content, f)\n# --- Basic CLI Tests ---\ndef test_cli_no_args_runs_with_defaults(temp_git_repo: Path):\n    \"\"\"Test running the CLI with no arguments in a simple repo. Expects defaults.\"\"\"\n    # Create a feature branch\n    repo = git.Repo(temp_git_repo)\n    repo.git.checkout(\"-b\", \"feature/good-branch\")",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_no_args_runs_with_defaults",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_no_args_runs_with_defaults(temp_git_repo: Path):\n    \"\"\"Test running the CLI with no arguments in a simple repo. Expects defaults.\"\"\"\n    # Create a feature branch\n    repo = git.Repo(temp_git_repo)\n    repo.git.checkout(\"-b\", \"feature/good-branch\")\n    (temp_git_repo / \"feature_file.txt\").write_text(\"Feature content\")\n    repo.index.add([\"feature_file.txt\"])\n    repo.index.commit(\"feat: add feature file\")\n    # Run CLI (should default to base=main, head=HEAD)\n    result = run_cli(temp_git_repo, [])",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_help_message",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_help_message():\n    \"\"\"Test if the CLI shows a help message.\"\"\"\n    # Run from anywhere, doesn't need a repo for --help\n    result = subprocess.run([\"python\", \"-m\", CLI_MODULE_PATH, \"--help\"], capture_output=True, text=True)\n    assert \"usage: cli.py\" in result.stdout # cli.py from argparse default prog name\n    assert \"--base-branch\" in result.stdout\n    assert result.returncode == 0\n# --- Policy Violation Tests ---\ndef test_cli_branch_name_violation(temp_git_repo: Path):\n    policy = {\"branch_naming\": {\"pattern\": \"^feature/.+$\", \"enabled\": True}}",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_branch_name_violation",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_branch_name_violation(temp_git_repo: Path):\n    policy = {\"branch_naming\": {\"pattern\": \"^feature/.+$\", \"enabled\": True}}\n    create_policy_file(temp_git_repo, policy)\n    repo = git.Repo(temp_git_repo)\n    repo.git.checkout(\"-b\", \"badbranchname\") # Does not match \"feature/.+\"\n    (temp_git_repo / \"f.txt\").write_text(\"content\")\n    repo.index.add([\"f.txt\"])\n    repo.index.commit(\"feat: some commit\")\n    result = run_cli(temp_git_repo, [\"--base-branch\", \"main\", \"--head-branch\", \"badbranchname\"])\n    # print(\"STDOUT:\", result.stdout)",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_commit_message_conventional_type_violation",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_commit_message_conventional_type_violation(temp_git_repo: Path):\n    policy = {\"commit_messages\": {\"conventional_commit\": {\"types\": [\"feat\", \"fix\"], \"enabled\": True}, \"enabled\": True}}\n    create_policy_file(temp_git_repo, policy)\n    repo = git.Repo(temp_git_repo)\n    repo.git.checkout(\"-b\", \"feature/test-conv-commit\")\n    (temp_git_repo / \"f.txt\").write_text(\"content\")\n    repo.index.add([\"f.txt\"])\n    repo.index.commit(\"docs: this type is not allowed by policy\") # 'docs' not in types\n    result = run_cli(temp_git_repo, [\"--base-branch\", \"main\", \"--head-branch\", \"feature/test-conv-commit\"])\n    # print(\"STDOUT:\", result.stdout)",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_commit_message_missing_issue_violation",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_commit_message_missing_issue_violation(temp_git_repo: Path):\n    policy = {\n        \"commit_messages\": {\n            \"require_issue_number\": {\"pattern\": \"TASK-\\\\d+\", \"in_commit_body\": True, \"enabled\": True},\n            \"enabled\": True\n        }\n    }\n    create_policy_file(temp_git_repo, policy)\n    repo = git.Repo(temp_git_repo)\n    repo.git.checkout(\"-b\", \"feature/test-issue\")",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_disallowed_pattern_violation",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_disallowed_pattern_violation(temp_git_repo: Path):\n    policy = {\n        \"disallowed_patterns\": {\n            \"patterns\": [{\"pattern\": \"DO_NOT_COMMIT\", \"message\": \"Found forbidden string\", \"enabled\": True}],\n            \"enabled\": True\n        }\n    }\n    create_policy_file(temp_git_repo, policy)\n    repo = git.Repo(temp_git_repo)\n    repo.git.checkout(\"-b\", \"feature/disallowed\")",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_file_size_violation",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_file_size_violation(temp_git_repo: Path):\n    policy = {\"file_size\": {\"max_bytes\": 100, \"enabled\": True}} # Max 100 bytes\n    create_policy_file(temp_git_repo, policy)\n    repo = git.Repo(temp_git_repo)\n    repo.git.checkout(\"-b\", \"feature/large-file\")\n    # Create a file larger than 100 bytes\n    large_content = \"a\" * 200\n    (temp_git_repo / \"large_file.txt\").write_text(large_content)\n    repo.index.add([\"large_file.txt\"])\n    repo.index.commit(\"feat: add large file\")",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_multiple_violations",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_multiple_violations(temp_git_repo: Path):\n    policy = {\n        \"branch_naming\": {\"pattern\": \"^feature/.+$\", \"enabled\": True},\n        \"commit_messages\": {\n            \"conventional_commit\": {\"types\": [\"feat\"], \"enabled\": True},\n            \"enabled\": True\n        },\n        \"file_size\": {\"max_bytes\": 50, \"enabled\": True}\n    }\n    create_policy_file(temp_git_repo, policy)",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_no_new_commits",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_no_new_commits(temp_git_repo: Path):\n    \"\"\" Test behavior when there are no new commits between base and head.\"\"\"\n    create_policy_file(temp_git_repo, {}) # Default policy\n    repo = git.Repo(temp_git_repo)\n    # main branch is already HEAD here as it's the only commit\n    result = run_cli(temp_git_repo, [\"--base-branch\", \"main\", \"--head-branch\", \"main\"])\n    # print(\"STDOUT:\", result.stdout)\n    # print(\"STDERR:\", result.stderr)\n    assert \"No new commits found between main and main.\" in result.stdout\n    assert \"ALL CHECKS PASSED\" in result.stdout # No commits means no commit/file violations",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "test_cli_non_existent_config_file",
        "kind": 2,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "def test_cli_non_existent_config_file(temp_git_repo: Path):\n    result = run_cli(temp_git_repo, [\"--config-file\", \"non_existent.yml\"])\n    # print(\"STDOUT:\", result.stdout)\n    # print(\"STDERR:\", result.stderr)\n    assert result.returncode != 0 # Should be 3 based on cli.py\n    assert \"Configuration file not found: non_existent.yml\" in result.stderr # Error message to stderr\n# More tests could include:\n# - Invalid repo path\n# - Invalid base/head branch names\n# - Config file with invalid YAML structure",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "CLI_MODULE_PATH",
        "kind": 5,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "CLI_MODULE_PATH = \"src.mcp_tools.pr_reviewer.cli\"\nDEFAULT_POLICY_FILENAME = \".pr-policy.yml\"\n@pytest.fixture\ndef temp_git_repo(tmp_path: Path):\n    \"\"\"\n    Fixture to create a temporary Git repository for testing.\n    Yields the path to the repository.\n    \"\"\"\n    repo_dir = tmp_path / \"test_repo\"\n    repo_dir.mkdir()",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "DEFAULT_POLICY_FILENAME",
        "kind": 5,
        "importPath": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "description": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "peekOfCode": "DEFAULT_POLICY_FILENAME = \".pr-policy.yml\"\n@pytest.fixture\ndef temp_git_repo(tmp_path: Path):\n    \"\"\"\n    Fixture to create a temporary Git repository for testing.\n    Yields the path to the repository.\n    \"\"\"\n    repo_dir = tmp_path / \"test_repo\"\n    repo_dir.mkdir()\n    # Initialize Git repo",
        "detail": "tests.integration.test_pr_reviewer.test_pr_reviewer_cli",
        "documentation": {}
    },
    {
        "label": "clear_context_store_after_each_test",
        "kind": 2,
        "importPath": "tests.integration.test_echo_tool",
        "description": "tests.integration.test_echo_tool",
        "peekOfCode": "def clear_context_store_after_each_test():\n    \"\"\"\n    Fixture to clear the CONTEXT_STORE after each test.\n    \"\"\"\n    CONTEXT_STORE.clear()\n    yield\n    CONTEXT_STORE.clear()\ndef test_echo_endpoint_direct():\n    \"\"\"\n    Test the /v1/tools/echo endpoint directly using TestClient.",
        "detail": "tests.integration.test_echo_tool",
        "documentation": {}
    },
    {
        "label": "test_echo_endpoint_direct",
        "kind": 2,
        "importPath": "tests.integration.test_echo_tool",
        "description": "tests.integration.test_echo_tool",
        "peekOfCode": "def test_echo_endpoint_direct():\n    \"\"\"\n    Test the /v1/tools/echo endpoint directly using TestClient.\n    \"\"\"\n    test_message = \"Hello, مباشر!\" # \"Hello, direct!\" in Arabic\n    payload = {\"message\": test_message}\n    response = client.post(\"/v1/tools/echo\", json=payload)\n    assert response.status_code == 200\n    assert response.json() == {\"echoed_message\": test_message, \"context_id\": None}\ndef test_echo_endpoint_direct_with_context():",
        "detail": "tests.integration.test_echo_tool",
        "documentation": {}
    },
    {
        "label": "test_echo_endpoint_direct_with_context",
        "kind": 2,
        "importPath": "tests.integration.test_echo_tool",
        "description": "tests.integration.test_echo_tool",
        "peekOfCode": "def test_echo_endpoint_direct_with_context():\n    \"\"\"\n    Test the /v1/tools/echo endpoint directly with a context_id.\n    \"\"\"\n    test_message = \"Hello, context!\"\n    context_id = \"test-context-123\"\n    # Optionally create the context first if the tool logic requires it\n    # client.post(\"/v1/contexts\", json={\"context_id\": context_id})\n    payload = {\"message\": test_message, \"context_id\": context_id}\n    response = client.post(\"/v1/tools/echo\", json=payload)",
        "detail": "tests.integration.test_echo_tool",
        "documentation": {}
    },
    {
        "label": "test_echo_tool_client_function",
        "kind": 2,
        "importPath": "tests.integration.test_echo_tool",
        "description": "tests.integration.test_echo_tool",
        "peekOfCode": "def test_echo_tool_client_function(monkeypatch):\n    \"\"\"\n    Test the call_echo_tool client function against the TestClient.\n    This is an integration test for the client utility.\n    \"\"\"\n    test_message = \"Hello, client function!\"\n    # The client function expects a full URL. TestClient doesn't run a live server on a port by default.\n    # We can use the TestClient's base_url or mock httpx.post to direct to the TestClient.\n    # For a true integration test of the client against the app, it's simpler to use TestClient as the server.\n    # Method 1: Use TestClient as if it were a server (requires client to be adaptable or server to be live)",
        "detail": "tests.integration.test_echo_tool",
        "documentation": {}
    },
    {
        "label": "test_echo_tool_client_function_with_context",
        "kind": 2,
        "importPath": "tests.integration.test_echo_tool",
        "description": "tests.integration.test_echo_tool",
        "peekOfCode": "def test_echo_tool_client_function_with_context(monkeypatch):\n    \"\"\"\n    Test the call_echo_tool client function with context_id against the TestClient.\n    \"\"\"\n    test_message = \"Client to context!\"\n    context_id = \"client-context-456\"\n    # client.post(f\"{client.base_url}/v1/contexts\", json={\"context_id\": context_id}) # Create context if necessary for tool\n    echo_response = call_echo_tool(\n        server_url=client.base_url,\n        message=test_message,",
        "detail": "tests.integration.test_echo_tool",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "tests.integration.test_echo_tool",
        "description": "tests.integration.test_echo_tool",
        "peekOfCode": "client = TestClient(app)\n@pytest.fixture(autouse=True)\ndef clear_context_store_after_each_test():\n    \"\"\"\n    Fixture to clear the CONTEXT_STORE after each test.\n    \"\"\"\n    CONTEXT_STORE.clear()\n    yield\n    CONTEXT_STORE.clear()\ndef test_echo_endpoint_direct():",
        "detail": "tests.integration.test_echo_tool",
        "documentation": {}
    },
    {
        "label": "create_ec2_resource",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def create_ec2_resource(id: str, name: str, instance_type: str, tags: Optional[Dict[str, str]] = None) -> ParsedResource:\n    return ParsedResource(\n        id=id, type=\"aws_instance\", name=name, provider_name=\"aws\",\n        attributes={\"instance_type\": instance_type, \"tags\": tags or {}}\n    )\n# --- Tests for check_ec2_instance_optimizations ---\ndef test_ec2_newer_generation_suggestion_from_map():\n    res = create_ec2_resource(\"i-t2\", \"test-t2\", \"t2.medium\")\n    rules = EC2InstanceTypeRule(suggest_newer_generations=True, generation_map={\"t2\": \"t3\"})\n    recs = check_ec2_instance_optimizations(res, rules)",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "test_ec2_newer_generation_suggestion_from_map",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def test_ec2_newer_generation_suggestion_from_map():\n    res = create_ec2_resource(\"i-t2\", \"test-t2\", \"t2.medium\")\n    rules = EC2InstanceTypeRule(suggest_newer_generations=True, generation_map={\"t2\": \"t3\"})\n    recs = check_ec2_instance_optimizations(res, rules)\n    assert len(recs) == 1\n    assert recs[0].rule_id == \"AWS_EC2_NEWER_GENERATION_MAPPED\"\n    assert \"'t2.medium'\" in recs[0].message\n    assert \"'t3.medium'\" in recs[0].message\ndef test_ec2_newer_generation_suggestion_generic_family():\n    res = create_ec2_resource(\"i-c3\", \"test-c3\", \"c3.large\") # Assume c3 is older, c4/c5/c6/c7 in default map",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "test_ec2_newer_generation_suggestion_generic_family",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def test_ec2_newer_generation_suggestion_generic_family():\n    res = create_ec2_resource(\"i-c3\", \"test-c3\", \"c3.large\") # Assume c3 is older, c4/c5/c6/c7 in default map\n    # Use default generation_map which doesn't have 'c3' explicitly, so it falls to generic family check\n    rules = EC2InstanceTypeRule(suggest_newer_generations=True)\n    # Ensure INSTANCE_FAMILY_GENERATION in ec2_optimizer.py has 'c3' or a similar setup for this test to be meaningful\n    # For this test, let's assume 'c3' is not in INSTANCE_FAMILY_GENERATION, so no generic suggestion for 'c' family\n    # If 'c3' *was* in INSTANCE_FAMILY_GENERATION and older than 'c4'/'c5', it would trigger.\n    # The current INSTANCE_FAMILY_GENERATION starts at gen 4 for 'c' family. So 'c3' would not match a family to find newer.\n    # Let's test with \"m3.large\" if m4/m5/m6/m7 are in map.\n    # Assuming \"m3\" is not in INSTANCE_FAMILY_GENERATION, but \"m\" family exists with newer.",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "test_ec2_newer_generation_already_newest_or_unmapped",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def test_ec2_newer_generation_already_newest_or_unmapped():\n    res = create_ec2_resource(\"i-m7g\", \"test-m7g\", \"m7g.large\") # m7g is latest in default map\n    rules = EC2InstanceTypeRule(suggest_newer_generations=True)\n    recs = check_ec2_instance_optimizations(res, rules)\n    assert not any(\"NEWER_GENERATION\" in r.rule_id for r in recs)\n    res_unknown = create_ec2_resource(\"i-custom\", \"test-custom\", \"custom.type\") # Not in map\n    recs_unknown = check_ec2_instance_optimizations(res_unknown, rules)\n    assert not any(\"NEWER_GENERATION\" in r.rule_id for r in recs_unknown)\ndef test_ec2_flag_large_instance_type():\n    res_large = create_ec2_resource(\"i-large\", \"test-large\", \"m5.24xlarge\") # In default large_instance_types_to_flag",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "test_ec2_flag_large_instance_type",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def test_ec2_flag_large_instance_type():\n    res_large = create_ec2_resource(\"i-large\", \"test-large\", \"m5.24xlarge\") # In default large_instance_types_to_flag\n    rules = EC2InstanceTypeRule(\n        large_instance_types_to_flag=[\"m5.24xlarge\"], # Explicitly list it for clarity\n        # flag_large_types_without_tag logic is simplified in current implementation\n    )\n    recs = check_ec2_instance_optimizations(res_large, rules)\n    assert len(recs) == 1\n    assert recs[0].rule_id == \"AWS_EC2_LARGE_INSTANCE_TYPE\"\n    assert \"'m5.24xlarge' is a large instance\" in recs[0].message",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "test_ec2_flag_large_instance_type_not_in_list",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def test_ec2_flag_large_instance_type_not_in_list():\n    res_medium = create_ec2_resource(\"i-medium\", \"test-medium\", \"m5.large\")\n    rules = EC2InstanceTypeRule(large_instance_types_to_flag=[\"c5.18xlarge\"]) # m5.large not in this list\n    recs = check_ec2_instance_optimizations(res_medium, rules)\n    assert not any(r.rule_id == \"AWS_EC2_LARGE_INSTANCE_TYPE\" for r in recs)\ndef test_ec2_no_instance_type_attribute():\n    res_no_type = ParsedResource(id=\"i-no-type\", type=\"aws_instance\", name=\"no-type-test\", provider_name=\"aws\", attributes={})\n    rules = EC2InstanceTypeRule()\n    recs = check_ec2_instance_optimizations(res_no_type, rules)\n    assert not recs # Should not generate recommendations if instance_type is missing",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "test_ec2_no_instance_type_attribute",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def test_ec2_no_instance_type_attribute():\n    res_no_type = ParsedResource(id=\"i-no-type\", type=\"aws_instance\", name=\"no-type-test\", provider_name=\"aws\", attributes={})\n    rules = EC2InstanceTypeRule()\n    recs = check_ec2_instance_optimizations(res_no_type, rules)\n    assert not recs # Should not generate recommendations if instance_type is missing\ndef test_ec2_rules_disabled():\n    res = create_ec2_resource(\"i-t2\", \"test-t2\", \"t2.medium\")\n    rules = EC2InstanceTypeRule(enabled=False, suggest_newer_generations=True) # Main rule disabled\n    recs = check_ec2_instance_optimizations(res, rules)\n    assert not recs",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "test_ec2_rules_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def test_ec2_rules_disabled():\n    res = create_ec2_resource(\"i-t2\", \"test-t2\", \"t2.medium\")\n    rules = EC2InstanceTypeRule(enabled=False, suggest_newer_generations=True) # Main rule disabled\n    recs = check_ec2_instance_optimizations(res, rules)\n    assert not recs\ndef test_ec2_suggest_newer_generations_disabled_in_rule():\n    res = create_ec2_resource(\"i-t2\", \"test-t2\", \"t2.medium\")\n    rules = EC2InstanceTypeRule(enabled=True, suggest_newer_generations=False) # Sub-rule disabled\n    recs = check_ec2_instance_optimizations(res, rules)\n    assert not any(\"NEWER_GENERATION\" in r.rule_id for r in recs)",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "test_ec2_suggest_newer_generations_disabled_in_rule",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "description": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "peekOfCode": "def test_ec2_suggest_newer_generations_disabled_in_rule():\n    res = create_ec2_resource(\"i-t2\", \"test-t2\", \"t2.medium\")\n    rules = EC2InstanceTypeRule(enabled=True, suggest_newer_generations=False) # Sub-rule disabled\n    recs = check_ec2_instance_optimizations(res, rules)\n    assert not any(\"NEWER_GENERATION\" in r.rule_id for r in recs)\n# Note: The 'flag_large_types_without_tag' logic in ec2_optimizer.py was simplified.\n# The current test 'test_ec2_flag_large_instance_type' reflects this simplified behavior\n# (flags if type is in list, message advises to check justification/tagging).\n# More complex tests for tag-based exemption would require updating the config model\n# and the implementation in ec2_optimizer.py for `flag_large_types_without_tag`.",
        "detail": "tests.unit.test_config_optimizer.test_ec2_optimizer",
        "documentation": {}
    },
    {
        "label": "temp_optimizer_rules_file",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def temp_optimizer_rules_file(tmp_path: Path):\n    \"\"\"Fixture to create a temporary optimizer rules file and clean it up.\"\"\"\n    file_path = tmp_path / DEFAULT_OPTIMIZER_RULES_FILENAME\n    def _create_config(content_dict):\n        with open(file_path, 'w') as f:\n            yaml.dump(content_dict, f)\n        return file_path\n    yield _create_config\n    # tmp_path handles cleanup\n# --- Test Default Values and Structure ---",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_default_optimizer_rule_config",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_default_optimizer_rule_config():\n    config = OptimizerRuleConfig()\n    assert isinstance(config.aws_ec2, AWSEC2Rules)\n    assert config.aws_ec2.enabled is True\n    assert isinstance(config.aws_ec2.instance_type_optimization, EC2InstanceTypeRule)\n    assert config.aws_ec2.instance_type_optimization.enabled is True\n    assert config.aws_ec2.instance_type_optimization.suggest_newer_generations is True\n    assert isinstance(config.aws_s3, AWSS3Rules)\n    assert config.aws_s3.enabled is True\n    assert isinstance(config.aws_s3.encryption, S3BucketEncryptionRule)",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_load_optimizer_rules_no_file_present",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_load_optimizer_rules_no_file_present():\n    \"\"\"Test loading when no config file exists; should return defaults.\"\"\"\n    # Ensure no default file exists in CWD for this test if CWD is part of search path\n    original_cwd = os.getcwd()\n    # Run in a temp dir that won't have the file unless we create it\n    with pytest.MonkeyPatch.context() as mp:\n        temp_dir = Path(original_cwd) / \"temp_test_dir_for_load_config_no_file\" # Avoid using tmp_path directly here to control CWD\n        temp_dir.mkdir(exist_ok=True)\n        mp.chdir(temp_dir)\n        try:",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_load_optimizer_rules_from_file",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_load_optimizer_rules_from_file(temp_optimizer_rules_file):\n    custom_rules_data = {\n        \"aws_ec2\": {\n            \"enabled\": True,\n            \"instance_type_optimization\": {\n                \"enabled\": True,\n                \"suggest_newer_generations\": False,\n                \"generation_map\": {\"t1\": \"t2\"},\n                \"large_instance_types_to_flag\": [\"m1.xlarge\"]\n            }",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_load_optimizer_rules_empty_file",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_load_optimizer_rules_empty_file(temp_optimizer_rules_file, capsys):\n    config_file_path = temp_optimizer_rules_file({}) # Empty dict -> empty YAML\n    config = load_optimizer_rules(str(config_file_path))\n    assert isinstance(config, OptimizerRuleConfig)\n    assert config.aws_ec2.enabled is True # Should be default\n    captured = capsys.readouterr()\n    assert \"Warning: Optimizer rules file\" in captured.out\n    assert \"is empty. Using default rules.\" in captured.out\ndef test_load_optimizer_rules_partial_config(temp_optimizer_rules_file):\n    partial_data = {",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_load_optimizer_rules_partial_config",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_load_optimizer_rules_partial_config(temp_optimizer_rules_file):\n    partial_data = {\n        \"aws_ec2\": {\n            \"instance_type_optimization\": {\"suggest_newer_generations\": False}\n        }\n        # aws_s3 section is missing, should use defaults\n    }\n    config_file_path = temp_optimizer_rules_file(partial_data)\n    config = load_optimizer_rules(str(config_file_path))\n    assert config.aws_ec2.instance_type_optimization.suggest_newer_generations is False",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_load_optimizer_rules_invalid_yaml",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_load_optimizer_rules_invalid_yaml(temp_optimizer_rules_file):\n    file_path = temp_optimizer_rules_file(None) # Create empty file\n    with open(file_path, 'w') as f:\n        f.write(\"aws_ec2: { instance_type_optimization: { enabled: true\") # Invalid YAML\n    with pytest.raises(ValueError, match=\"Error parsing YAML optimizer rules file\"):\n        load_optimizer_rules(str(file_path))\ndef test_load_optimizer_rules_validation_error(temp_optimizer_rules_file):\n    invalid_data = {\n        \"aws_ec2\": {\n            \"instance_type_optimization\": {\"suggest_newer_generations\": \"not-a-boolean\"}",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_load_optimizer_rules_validation_error",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_load_optimizer_rules_validation_error(temp_optimizer_rules_file):\n    invalid_data = {\n        \"aws_ec2\": {\n            \"instance_type_optimization\": {\"suggest_newer_generations\": \"not-a-boolean\"}\n        }\n    }\n    config_file_path = temp_optimizer_rules_file(invalid_data)\n    with pytest.raises(ValueError, match=\"Optimizer rules validation error\"):\n        load_optimizer_rules(str(config_file_path))\ndef test_default_file_search_logic_optimizer(tmp_path: Path):",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_default_file_search_logic_optimizer",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_default_file_search_logic_optimizer(tmp_path: Path):\n    \"\"\"Test the search logic for the default optimizer rules file.\"\"\"\n    project_root = tmp_path\n    sub_dir = project_root / \"project_A\" / \"module_B\"\n    sub_dir.mkdir(parents=True)\n    rules_content = {\"aws_s3\": {\"versioning\": {\"enabled\": False}}}\n    with open(project_root / DEFAULT_OPTIMIZER_RULES_FILENAME, 'w') as f: # Place in project_root\n        yaml.dump(rules_content, f)\n    original_cwd = os.getcwd()\n    os.chdir(sub_dir) # Run from a subdirectory",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "test_load_optimizer_rules_explicit_path_not_found",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_optimizer_config",
        "description": "tests.unit.test_config_optimizer.test_optimizer_config",
        "peekOfCode": "def test_load_optimizer_rules_explicit_path_not_found(capsys):\n    config = load_optimizer_rules(config_path=\"non_existent_rules.yml\")\n    assert config.aws_ec2.enabled is True # Defaults are used\n    captured = capsys.readouterr()\n    assert \"Warning: Optimizer rules file 'non_existent_rules.yml' not found. Using default rules.\" in captured.out",
        "detail": "tests.unit.test_config_optimizer.test_optimizer_config",
        "documentation": {}
    },
    {
        "label": "create_s3_resource",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def create_s3_resource(id: str, name: str, attributes: Dict[str, Any]) -> ParsedResource:\n    return ParsedResource(\n        id=id, type=\"aws_s3_bucket\", name=name, provider_name=\"aws\", attributes=attributes\n    )\n# --- Tests for check_s3_bucket_optimizations ---\n# 1. Encryption Tests\ndef test_s3_encryption_not_configured():\n    res = create_s3_resource(\"bucket-no-sse\", \"no-sse\", {\"bucket\": \"bucket-no-sse\"})\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=True, require_sse_kms=False))\n    recs = check_s3_bucket_optimizations(res, rules)",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_encryption_not_configured",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_encryption_not_configured():\n    res = create_s3_resource(\"bucket-no-sse\", \"no-sse\", {\"bucket\": \"bucket-no-sse\"})\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=True, require_sse_kms=False))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert any(r.rule_id == \"AWS_S3_ENCRYPTION_DISABLED\" for r in recs)\ndef test_s3_encryption_aes256_ok_when_kms_not_required():\n    res_attrs = {\"server_side_encryption_configuration\": {\"rule\": {\"apply_server_side_encryption_by_default\": {\"sse_algorithm\": \"AES256\"}}}}\n    res = create_s3_resource(\"bucket-aes\", \"aes-bucket\", res_attrs)\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=True, require_sse_kms=False))\n    recs = check_s3_bucket_optimizations(res, rules)",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_encryption_aes256_ok_when_kms_not_required",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_encryption_aes256_ok_when_kms_not_required():\n    res_attrs = {\"server_side_encryption_configuration\": {\"rule\": {\"apply_server_side_encryption_by_default\": {\"sse_algorithm\": \"AES256\"}}}}\n    res = create_s3_resource(\"bucket-aes\", \"aes-bucket\", res_attrs)\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=True, require_sse_kms=False))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_ENCRYPTION_DISABLED\" for r in recs)\ndef test_s3_encryption_aes256_fail_when_kms_required():\n    res_attrs = {\"server_side_encryption_configuration\": {\"rule\": {\"apply_server_side_encryption_by_default\": {\"sse_algorithm\": \"AES256\"}}}}\n    res = create_s3_resource(\"bucket-aes-kms-fail\", \"aes-kms-fail\", res_attrs)\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=True, require_sse_kms=True))",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_encryption_aes256_fail_when_kms_required",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_encryption_aes256_fail_when_kms_required():\n    res_attrs = {\"server_side_encryption_configuration\": {\"rule\": {\"apply_server_side_encryption_by_default\": {\"sse_algorithm\": \"AES256\"}}}}\n    res = create_s3_resource(\"bucket-aes-kms-fail\", \"aes-kms-fail\", res_attrs)\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=True, require_sse_kms=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert any(r.rule_id == \"AWS_S3_ENCRYPTION_DISABLED\" for r in recs)\ndef test_s3_encryption_kms_ok_when_kms_required():\n    res_attrs = {\"server_side_encryption_configuration\": {\"rule\": {\"apply_server_side_encryption_by_default\": {\"sse_algorithm\": \"aws:kms\", \"kms_master_key_id\": \"alias/aws/s3\"}}}}\n    res = create_s3_resource(\"bucket-kms-ok\", \"kms-ok\", res_attrs)\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=True, require_sse_kms=True))",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_encryption_kms_ok_when_kms_required",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_encryption_kms_ok_when_kms_required():\n    res_attrs = {\"server_side_encryption_configuration\": {\"rule\": {\"apply_server_side_encryption_by_default\": {\"sse_algorithm\": \"aws:kms\", \"kms_master_key_id\": \"alias/aws/s3\"}}}}\n    res = create_s3_resource(\"bucket-kms-ok\", \"kms-ok\", res_attrs)\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=True, require_sse_kms=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_ENCRYPTION_DISABLED\" for r in recs)\ndef test_s3_encryption_rule_disabled():\n    res = create_s3_resource(\"bucket-no-sse-rule-off\", \"no-sse-rule-off\", {})\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=False))\n    recs = check_s3_bucket_optimizations(res, rules)",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_encryption_rule_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_encryption_rule_disabled():\n    res = create_s3_resource(\"bucket-no-sse-rule-off\", \"no-sse-rule-off\", {})\n    rules = AWSS3Rules(encryption=S3BucketEncryptionRule(enabled=False))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_ENCRYPTION_DISABLED\" for r in recs)\n# 2. Versioning Tests\ndef test_s3_versioning_not_configured():\n    res = create_s3_resource(\"bucket-no-ver\", \"no-ver\", {\"bucket\": \"bucket-no-ver\"})\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=True))\n    recs = check_s3_bucket_optimizations(res, rules)",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_versioning_not_configured",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_versioning_not_configured():\n    res = create_s3_resource(\"bucket-no-ver\", \"no-ver\", {\"bucket\": \"bucket-no-ver\"})\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert any(r.rule_id == \"AWS_S3_VERSIONING_DISABLED\" for r in recs)\ndef test_s3_versioning_explicitly_disabled_tf_style(): # TF state: list of dicts\n    res_attrs = {\"versioning\": [{\"enabled\": False, \"mfa_delete\": False}]}\n    res = create_s3_resource(\"bucket-ver-off-tf\", \"ver-off-tf\", res_attrs)\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=True))\n    recs = check_s3_bucket_optimizations(res, rules)",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_versioning_explicitly_disabled_tf_style",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_versioning_explicitly_disabled_tf_style(): # TF state: list of dicts\n    res_attrs = {\"versioning\": [{\"enabled\": False, \"mfa_delete\": False}]}\n    res = create_s3_resource(\"bucket-ver-off-tf\", \"ver-off-tf\", res_attrs)\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert any(r.rule_id == \"AWS_S3_VERSIONING_DISABLED\" for r in recs)\ndef test_s3_versioning_enabled_tf_style():\n    res_attrs = {\"versioning\": [{\"enabled\": True, \"mfa_delete\": False}]}\n    res = create_s3_resource(\"bucket-ver-on-tf\", \"ver-on-tf\", res_attrs)\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=True))",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_versioning_enabled_tf_style",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_versioning_enabled_tf_style():\n    res_attrs = {\"versioning\": [{\"enabled\": True, \"mfa_delete\": False}]}\n    res = create_s3_resource(\"bucket-ver-on-tf\", \"ver-on-tf\", res_attrs)\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_VERSIONING_DISABLED\" for r in recs)\ndef test_s3_versioning_enabled_api_style(): # API response: direct dict\n    res_attrs = {\"versioning\": {\"status\": \"Enabled\"}} # or \"enabled\": True\n    res = create_s3_resource(\"bucket-ver-on-api\", \"ver-on-api\", res_attrs)\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=True))",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_versioning_enabled_api_style",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_versioning_enabled_api_style(): # API response: direct dict\n    res_attrs = {\"versioning\": {\"status\": \"Enabled\"}} # or \"enabled\": True\n    res = create_s3_resource(\"bucket-ver-on-api\", \"ver-on-api\", res_attrs)\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_VERSIONING_DISABLED\" for r in recs)\n    res_attrs_enabled_true = {\"versioning\": {\"enabled\": True}}\n    res_enabled_true = create_s3_resource(\"bucket-ver-on-api2\", \"ver-on-api2\", res_attrs_enabled_true)\n    recs2 = check_s3_bucket_optimizations(res_enabled_true, rules)\n    assert not any(r.rule_id == \"AWS_S3_VERSIONING_DISABLED\" for r in recs2)",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_versioning_rule_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_versioning_rule_disabled():\n    res = create_s3_resource(\"bucket-no-ver-rule-off\", \"no-ver-rule-off\", {})\n    rules = AWSS3Rules(versioning=S3BucketVersioningRule(enabled=False))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_VERSIONING_DISABLED\" for r in recs)\n# 3. Public Access Block Tests\ndef test_s3_pab_not_configured():\n    res = create_s3_resource(\"bucket-no-pab\", \"no-pab\", {\"bucket\": \"bucket-no-pab\"})\n    rules = AWSS3Rules(public_access_block=S3BucketPublicAccessBlockRule(enabled=True, require_all_blocks_true=True))\n    recs = check_s3_bucket_optimizations(res, rules)",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_pab_not_configured",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_pab_not_configured():\n    res = create_s3_resource(\"bucket-no-pab\", \"no-pab\", {\"bucket\": \"bucket-no-pab\"})\n    rules = AWSS3Rules(public_access_block=S3BucketPublicAccessBlockRule(enabled=True, require_all_blocks_true=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert any(r.rule_id == \"AWS_S3_PUBLIC_ACCESS_BLOCK_INCOMPLETE\" for r in recs)\ndef test_s3_pab_partially_configured_false(): # TF style list of dicts\n    res_attrs = {\"public_access_block\": [{\n        \"block_public_acls\": True, \"block_public_policy\": False, # This one is False\n        \"ignore_public_acls\": True, \"restrict_public_buckets\": True\n    }]}",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_pab_partially_configured_false",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_pab_partially_configured_false(): # TF style list of dicts\n    res_attrs = {\"public_access_block\": [{\n        \"block_public_acls\": True, \"block_public_policy\": False, # This one is False\n        \"ignore_public_acls\": True, \"restrict_public_buckets\": True\n    }]}\n    res = create_s3_resource(\"bucket-pab-partial\", \"pab-partial\", res_attrs)\n    rules = AWSS3Rules(public_access_block=S3BucketPublicAccessBlockRule(enabled=True, require_all_blocks_true=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert any(r.rule_id == \"AWS_S3_PUBLIC_ACCESS_BLOCK_INCOMPLETE\" for r in recs)\n    assert \"block_public_policy\" in recs[-1].details.get(\"blocks_not_fully_enabled\", {}) # Assuming it's the last rec",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_pab_partially_configured_missing",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_pab_partially_configured_missing(): # Direct dict style\n    res_attrs = {\"public_access_block\": {\n        \"block_public_acls\": True, # block_public_policy is missing\n        \"ignore_public_acls\": True, \"restrict_public_buckets\": True\n    }}\n    res = create_s3_resource(\"bucket-pab-missing\", \"pab-missing\", res_attrs)\n    rules = AWSS3Rules(public_access_block=S3BucketPublicAccessBlockRule(enabled=True, require_all_blocks_true=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert any(r.rule_id == \"AWS_S3_PUBLIC_ACCESS_BLOCK_INCOMPLETE\" for r in recs)\n    assert \"block_public_policy\" in recs[-1].details.get(\"blocks_not_fully_enabled\", {})",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_pab_all_true_tf_style",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_pab_all_true_tf_style():\n    res_attrs = {\"public_access_block\": [{\n        \"block_public_acls\": True, \"block_public_policy\": True,\n        \"ignore_public_acls\": True, \"restrict_public_buckets\": True\n    }]}\n    res = create_s3_resource(\"bucket-pab-good-tf\", \"pab-good-tf\", res_attrs)\n    rules = AWSS3Rules(public_access_block=S3BucketPublicAccessBlockRule(enabled=True, require_all_blocks_true=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_PUBLIC_ACCESS_BLOCK_INCOMPLETE\" for r in recs)\ndef test_s3_pab_all_true_direct_dict_style():",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_pab_all_true_direct_dict_style",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_pab_all_true_direct_dict_style():\n    res_attrs = {\"public_access_block\": {\n        \"block_public_acls\": True, \"block_public_policy\": True,\n        \"ignore_public_acls\": True, \"restrict_public_buckets\": True\n    }}\n    res = create_s3_resource(\"bucket-pab-good-dict\", \"pab-good-dict\", res_attrs)\n    rules = AWSS3Rules(public_access_block=S3BucketPublicAccessBlockRule(enabled=True, require_all_blocks_true=True))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_PUBLIC_ACCESS_BLOCK_INCOMPLETE\" for r in recs)\ndef test_s3_pab_rule_disabled():",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_pab_rule_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_pab_rule_disabled():\n    res = create_s3_resource(\"bucket-no-pab-rule-off\", \"no-pab-rule-off\", {})\n    rules = AWSS3Rules(public_access_block=S3BucketPublicAccessBlockRule(enabled=False))\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not any(r.rule_id == \"AWS_S3_PUBLIC_ACCESS_BLOCK_INCOMPLETE\" for r in recs)\ndef test_s3_all_aws_s3_rules_disabled():\n    res = create_s3_resource(\"bucket-all-s3-off\", \"all-s3-off\", {}) # Will fail all checks if enabled\n    rules = AWSS3Rules(enabled=False) # Disable all S3 checks at parent level\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not recs",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_s3_all_aws_s3_rules_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "description": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "peekOfCode": "def test_s3_all_aws_s3_rules_disabled():\n    res = create_s3_resource(\"bucket-all-s3-off\", \"all-s3-off\", {}) # Will fail all checks if enabled\n    rules = AWSS3Rules(enabled=False) # Disable all S3 checks at parent level\n    recs = check_s3_bucket_optimizations(res, rules)\n    assert not recs",
        "detail": "tests.unit.test_config_optimizer.test_s3_optimizer",
        "documentation": {}
    },
    {
        "label": "test_format_value",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_format_value(input_val, expected_str):\n    assert format_value(input_val) == expected_str\n# --- Test MarkdownRenderer ---\n@pytest.fixture\ndef sample_module_doc_data() -> TerraformModuleProcessedDoc:\n    var1 = TerraformVariableDoc(name=\"instance_count\", type=\"number\", description=\"Number of instances.\", default=1)\n    var2 = TerraformVariableDoc(name=\"image_id\", type=\"string\", description=\"AMI ID. Pipe | char test.\", is_sensitive=True) # Required\n    out1 = TerraformOutputDoc(name=\"instance_ips\", description=\"Public IPs.\", is_sensitive=False)\n    out2 = TerraformOutputDoc(name=\"app_url\", description=\"Application URL.\", is_sensitive=True)\n    res1 = TerraformResourceDoc(resource_type=\"aws_instance\", resource_name=\"web_app\", source_file=\"main.tf\")",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "sample_module_doc_data",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def sample_module_doc_data() -> TerraformModuleProcessedDoc:\n    var1 = TerraformVariableDoc(name=\"instance_count\", type=\"number\", description=\"Number of instances.\", default=1)\n    var2 = TerraformVariableDoc(name=\"image_id\", type=\"string\", description=\"AMI ID. Pipe | char test.\", is_sensitive=True) # Required\n    out1 = TerraformOutputDoc(name=\"instance_ips\", description=\"Public IPs.\", is_sensitive=False)\n    out2 = TerraformOutputDoc(name=\"app_url\", description=\"Application URL.\", is_sensitive=True)\n    res1 = TerraformResourceDoc(resource_type=\"aws_instance\", resource_name=\"web_app\", source_file=\"main.tf\")\n    res2 = TerraformResourceDoc(resource_type=\"aws_s3_bucket\", resource_name=\"app_storage\", source_file=\"s3.tf\")\n    modcall1 = TerraformModuleCallDoc(module_name=\"networking\", source=\"./modules/vpc\", source_file=\"main.tf\")\n    prov1 = TerraformProviderDoc(name=\"aws\", alias=\"primary\", source_file=\"main.tf\")\n    prov2 = TerraformProviderDoc(name=\"random\", source_file=\"main.tf\")",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_module_header",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_module_header(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"# Terraform Module: `path`\" in md # Basename of module_path\n    assert \"**Path:** `/test/module/path`\" in md\n    assert \"A test Terraform module.\" in md # Module description\ndef test_markdown_renderer_file_sections(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"## File: `main.tf`\" in md",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_file_sections",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_file_sections(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"## File: `main.tf`\" in md\n    assert \"Main infrastructure setup.\" in md # File description\n    assert \"## File: `variables.tf`\" in md\n    assert \"## File: `outputs.tf`\" in md\n    assert \"## File: `s3.tf`\" in md\n    assert \"---\" in md # Separator\ndef test_markdown_renderer_providers_section(sample_module_doc_data: TerraformModuleProcessedDoc):",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_providers_section",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_providers_section(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"### Providers\" in md\n    assert \"- `aws` (alias: `primary`)\" in md\n    assert \"- `random`\" in md\ndef test_markdown_renderer_variables_section(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"### Variables\" in md",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_variables_section",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_variables_section(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"### Variables\" in md\n    assert \"| Name | Description | Type | Default | Sensitive |\" in md\n    assert \"| `image_id` | AMI ID. Pipe \\\\| char test. | `string` | *(Required)* | `True` |\" in md\n    assert \"| `instance_count` | Number of instances. | `number` | `1` | `False` |\" in md\ndef test_markdown_renderer_outputs_section(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_outputs_section",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_outputs_section(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"### Outputs\" in md\n    assert \"| Name | Description | Sensitive |\" in md\n    assert \"| `app_url` | Application URL. | `True` |\" in md\n    assert \"| `instance_ips` | Public IPs. | `False` |\" in md\ndef test_markdown_renderer_resources_section(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_resources_section",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_resources_section(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"### Managed Resources\" in md\n    # Check for resources from main.tf\n    assert \"- **`aws_instance.web_app`**\" in md\n    # Check for resources from s3.tf (should be under its own file section)\n    assert \"## File: `s3.tf`\" in md # Ensure s3.tf section exists\n    # Find \"Managed Resources\" header specifically under s3.tf section\n    s3_tf_section_start = md.find(\"## File: `s3.tf`\")",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_module_calls_section",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_module_calls_section(sample_module_doc_data: TerraformModuleProcessedDoc):\n    renderer = MarkdownRenderer(sample_module_doc_data)\n    md = renderer.render_module_documentation()\n    assert \"### Module Calls\" in md\n    assert \"- **`networking`** (Source: `./modules/vpc`)\" in md\ndef test_markdown_renderer_empty_sections_not_rendered():\n    file_empty = TerraformFileDoc(file_path=\"empty.tf\")\n    module_doc = TerraformModuleProcessedDoc(module_path=\"/empty/module\", files=[file_empty])\n    renderer = MarkdownRenderer(module_doc)\n    md = renderer.render_module_documentation()",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_empty_sections_not_rendered",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_empty_sections_not_rendered():\n    file_empty = TerraformFileDoc(file_path=\"empty.tf\")\n    module_doc = TerraformModuleProcessedDoc(module_path=\"/empty/module\", files=[file_empty])\n    renderer = MarkdownRenderer(module_doc)\n    md = renderer.render_module_documentation()\n    assert \"## File: `empty.tf`\" in md\n    assert \"### Variables\" not in md # Because file_empty.variables is empty\n    assert \"### Outputs\" not in md\n    assert \"### Managed Resources\" not in md\n    assert \"### Module Calls\" not in md",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_markdown_renderer_no_files",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "description": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "peekOfCode": "def test_markdown_renderer_no_files():\n    module_doc = TerraformModuleProcessedDoc(module_path=\"/no_files/module\", files=[])\n    renderer = MarkdownRenderer(module_doc)\n    md = renderer.render_module_documentation()\n    assert \"# Terraform Module: `module`\" in md # Basename should still work\n    assert \"## File:\" not in md # No file sections\n    assert \"---\" not in md",
        "detail": "tests.unit.test_iac_doc_generator.test_markdown_renderer",
        "documentation": {}
    },
    {
        "label": "test_extract_string_or_first_from_list",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_extract_string_or_first_from_list():\n    assert _extract_string_or_first_from_list([\"hello\"]) == \"hello\"\n    assert _extract_string_or_first_from_list(\"world\") == \"world\"\n    assert _extract_string_or_first_from_list(123) == \"123\"\n    assert _extract_string_or_first_from_list(True) == \"True\"\n    assert _extract_string_or_first_from_list(None) is None\n    assert _extract_string_or_first_from_list([\"hello\", \"world\"]) == \"['hello', 'world']\" # Default str conversion for >1 item list\ndef test_extract_description_from_block_body():\n    assert _extract_description_from_block_body({\"description\": \"Test desc\"}) == \"Test desc\"\n    assert _extract_description_from_block_body({\"description\": [\"Test desc list\"]}) == \"Test desc list\"",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_extract_description_from_block_body",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_extract_description_from_block_body():\n    assert _extract_description_from_block_body({\"description\": \"Test desc\"}) == \"Test desc\"\n    assert _extract_description_from_block_body({\"description\": [\"Test desc list\"]}) == \"Test desc list\"\n    assert _extract_description_from_block_body({}) is None\n    assert _extract_description_from_block_body({\"description\": [\"Item1\", \"Item2\"]}) is None # Expects single item list\n# --- Tests for parse_hcl_file_content ---\n@pytest.fixture\ndef sample_hcl_content_main() -> str:\n    return \"\"\"\nprovider \"aws\" {",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "sample_hcl_content_main",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def sample_hcl_content_main() -> str:\n    return \"\"\"\nprovider \"aws\" {\n  region = \"us-west-2\"\n  alias  = \"west\"\n}\nresource \"aws_instance\" \"my_server\" {\n  ami           = \"ami-abcdef12\"\n  instance_type = \"t3.micro\"\n  tags = { Name = \"MyServer\" }",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "sample_hcl_content_variables",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def sample_hcl_content_variables() -> str:\n    return \"\"\"\nvariable \"instance_name\" {\n  description = \"Name for the EC2 instance\"\n  type        = string\n  default     = \"DefaultServerName\"\n}\nvariable \"is_prod\" {\n  type        = bool\n  default     = false",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "sample_hcl_content_outputs",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def sample_hcl_content_outputs() -> str:\n    return \"\"\"\noutput \"server_ip\" {\n  description = \"Public IP of the server\"\n  value       = aws_instance.my_server.public_ip\n}\noutput \"vpc_id\" {\n  value       = module.my_vpc.vpc_id\n  sensitive   = true\n}",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_hcl_main_tf_content",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_hcl_main_tf_content(sample_hcl_content_main):\n    file_doc = parse_hcl_file_content(sample_hcl_content_main, \"main.tf\")\n    assert len(file_doc.providers) == 1\n    assert file_doc.providers[0].name == \"aws\"\n    assert file_doc.providers[0].alias == \"west\"\n    assert len(file_doc.resources) == 1\n    assert file_doc.resources[0].resource_type == \"aws_instance\"\n    assert file_doc.resources[0].resource_name == \"my_server\"\n    assert file_doc.resources[0].source_file == \"main.tf\"\n    assert len(file_doc.module_calls) == 1",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_hcl_variables_tf_content",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_hcl_variables_tf_content(sample_hcl_content_variables):\n    file_doc = parse_hcl_file_content(sample_hcl_content_variables, \"variables.tf\")\n    assert len(file_doc.variables) == 3\n    var_instance_name = next(v for v in file_doc.variables if v.name == \"instance_name\")\n    assert var_instance_name.description == \"Name for the EC2 instance\"\n    assert var_instance_name.type == \"string\"\n    assert var_instance_name.default == \"DefaultServerName\"\n    assert var_instance_name.is_sensitive is False\n    var_is_prod = next(v for v in file_doc.variables if v.name == \"is_prod\")\n    assert var_is_prod.type == \"bool\"",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_hcl_outputs_tf_content",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_hcl_outputs_tf_content(sample_hcl_content_outputs):\n    file_doc = parse_hcl_file_content(sample_hcl_content_outputs, \"outputs.tf\")\n    assert len(file_doc.outputs) == 2\n    out_server_ip = next(o for o in file_doc.outputs if o.name == \"server_ip\")\n    assert out_server_ip.description == \"Public IP of the server\"\n    assert out_server_ip.is_sensitive is False\n    out_vpc_id = next(o for o in file_doc.outputs if o.name == \"vpc_id\")\n    assert out_vpc_id.description is None\n    assert out_vpc_id.is_sensitive is True\ndef test_parse_hcl_empty_content():",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_hcl_empty_content",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_hcl_empty_content():\n    file_doc = parse_hcl_file_content(\"\", \"empty.tf\")\n    assert not file_doc.variables\n    assert not file_doc.outputs\n    assert not file_doc.resources\n    assert not file_doc.module_calls\n    assert not file_doc.providers\ndef test_parse_hcl_invalid_syntax(capsys):\n    file_doc = parse_hcl_file_content(\"resource 'invalid' {}\", \"invalid.tf\") # Missing \"\n    captured = capsys.readouterr()",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_hcl_invalid_syntax",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_hcl_invalid_syntax(capsys):\n    file_doc = parse_hcl_file_content(\"resource 'invalid' {}\", \"invalid.tf\") # Missing \"\n    captured = capsys.readouterr()\n    assert \"Warning: Could not parse HCL file invalid.tf\" in captured.err\n    # File_doc will still be created but empty of parsed elements\n    assert file_doc.file_path == \"invalid.tf\"\n    assert not file_doc.resources\n# --- Tests for parse_terraform_module_directory ---\n@pytest.fixture\ndef temp_tf_module(tmp_path: Path, sample_hcl_content_main, sample_hcl_content_variables, sample_hcl_content_outputs):",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "temp_tf_module",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def temp_tf_module(tmp_path: Path, sample_hcl_content_main, sample_hcl_content_variables, sample_hcl_content_outputs):\n    module_dir = tmp_path / \"test_module\"\n    module_dir.mkdir()\n    (module_dir / \"main.tf\").write_text(sample_hcl_content_main)\n    (module_dir / \"variables.tf\").write_text(sample_hcl_content_variables)\n    (module_dir / \"outputs.tf\").write_text(sample_hcl_content_outputs)\n    (module_dir / \"other.txt\").write_text(\"This is not a tf file.\") # Should be ignored\n    return module_dir\ndef test_parse_terraform_module_directory_valid(temp_tf_module: Path):\n    module_doc = parse_terraform_module_directory(str(temp_tf_module))",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_terraform_module_directory_valid",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_terraform_module_directory_valid(temp_tf_module: Path):\n    module_doc = parse_terraform_module_directory(str(temp_tf_module))\n    assert module_doc.module_path == str(temp_tf_module.resolve())\n    assert len(module_doc.files) == 3 # main.tf, variables.tf, outputs.tf\n    main_tf_file_doc = next((f for f in module_doc.files if f.file_path == \"main.tf\"), None)\n    assert main_tf_file_doc is not None\n    assert len(main_tf_file_doc.resources) == 1\n    assert len(main_tf_file_doc.module_calls) == 1\n    assert len(main_tf_file_doc.providers) == 1\n    variables_tf_file_doc = next((f for f in module_doc.files if f.file_path == \"variables.tf\"), None)",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_terraform_module_directory_empty",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_terraform_module_directory_empty(tmp_path: Path):\n    empty_module_dir = tmp_path / \"empty_module\"\n    empty_module_dir.mkdir()\n    module_doc = parse_terraform_module_directory(str(empty_module_dir))\n    assert len(module_doc.files) == 0\ndef test_parse_terraform_module_directory_not_a_directory(tmp_path: Path):\n    not_a_dir = tmp_path / \"not_a_dir.txt\"\n    not_a_dir.write_text(\"hello\")\n    with pytest.raises(ValueError, match=\"Provided path is not a directory\"):\n        parse_terraform_module_directory(str(not_a_dir))",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_terraform_module_directory_not_a_directory",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_terraform_module_directory_not_a_directory(tmp_path: Path):\n    not_a_dir = tmp_path / \"not_a_dir.txt\"\n    not_a_dir.write_text(\"hello\")\n    with pytest.raises(ValueError, match=\"Provided path is not a directory\"):\n        parse_terraform_module_directory(str(not_a_dir))\ndef test_parse_terraform_module_directory_file_with_parsing_error(tmp_path: Path, capsys):\n    module_dir_with_error = tmp_path / \"module_with_error\"\n    module_dir_with_error.mkdir()\n    (module_dir_with_error / \"good.tf\").write_text('resource \"null_resource\" \"good\" {}')\n    (module_dir_with_error / \"bad.tf\").write_text('resource \"invalid_syntax {}') # Missing quote",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_terraform_module_directory_file_with_parsing_error",
        "kind": 2,
        "importPath": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "description": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "peekOfCode": "def test_parse_terraform_module_directory_file_with_parsing_error(tmp_path: Path, capsys):\n    module_dir_with_error = tmp_path / \"module_with_error\"\n    module_dir_with_error.mkdir()\n    (module_dir_with_error / \"good.tf\").write_text('resource \"null_resource\" \"good\" {}')\n    (module_dir_with_error / \"bad.tf\").write_text('resource \"invalid_syntax {}') # Missing quote\n    module_doc = parse_terraform_module_directory(str(module_dir_with_error))\n    assert len(module_doc.files) == 2 # Both files attempted, one will be mostly empty\n    good_file_doc = next((f for f in module_doc.files if f.file_path == \"good.tf\"), None)\n    assert good_file_doc is not None\n    assert len(good_file_doc.resources) == 1",
        "detail": "tests.unit.test_iac_doc_generator.test_terraform_hcl_parser",
        "documentation": {}
    },
    {
        "label": "test_compare_attributes",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_attributes(iac_attrs, actual_attrs, resource_type, ignored_config, expected_drifts_count, expected_drift_details):\n    drifts = compare_attributes(iac_attrs, actual_attrs, resource_type, ignored_config)\n    assert len(drifts) == expected_drifts_count\n    for i, (attr_name, iac_val, act_val) in enumerate(expected_drift_details):\n        found_drift = next((d for d in drifts if d.attribute_name == attr_name), None)\n        assert found_drift is not None, f\"Expected drift for attribute '{attr_name}' not found.\"\n        assert found_drift.iac_value == iac_val\n        assert found_drift.actual_value == act_val\n# --- Test compare_states ---\ndef test_compare_states_modified_missing_unmanaged():",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_compare_states_modified_missing_unmanaged",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_states_modified_missing_unmanaged():\n    iac_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-instance-01\", type=\"vm\", name=\"web_server_iac\", provider_name=\"mock\", attributes={\"size\": \"medium\", \"image\": \"ubuntu-20.04\", \"tags\": {\"env\": \"prod\"}}),\n        ParsedResource(id=\"id-db-01\", type=\"database\", name=\"main_db_iac\", provider_name=\"mock\", attributes={\"version\": \"12\", \"storage\": \"100GB\"}), # Missing\n    ]\n    actual_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-instance-01\", type=\"vm\", name=\"web_server_actual\", provider_name=\"mock\", attributes={\"size\": \"large\", \"image\": \"ubuntu-20.04\", \"tags\": {\"env\": \"prod\", \"extra_tag\": \"hello\"}}), # Modified size\n        ParsedResource(id=\"id-disk-unmanaged\", type=\"disk\", name=\"orphan_disk_actual\", provider_name=\"mock\", attributes={\"size\": \"50GB\"}), # Unmanaged\n    ]\n    drifts = compare_states(iac_state, actual_state)",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_compare_states_no_drift",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_states_no_drift():\n    iac_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-vm-100\", type=\"vm\", name=\"app_server\", provider_name=\"mock\", attributes={\"image\": \"centos8\", \"cpu\": 2}),\n    ]\n    actual_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-vm-100\", type=\"vm\", name=\"app_server_live\", provider_name=\"mock\", attributes={\"image\": \"centos8\", \"cpu\": 2}),\n    ]\n    drifts = compare_states(iac_state, actual_state)\n    assert not drifts, f\"Expected no drift, but got: {drifts}\"\ndef test_compare_states_ignored_attributes():",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_compare_states_ignored_attributes",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_states_ignored_attributes():\n    custom_ignored = {\"vm\": [\"last_updated_time\", \"dynamic_ip\"]}\n    iac_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-vm-200\", type=\"vm\", name=\"worker\", provider_name=\"mock\",\n                    attributes={\"image\": \"debian\", \"ram\": \"4GB\", \"last_updated_time\": \"ts1\", \"tags\": {\"managed_by\": \"iac\"}}),\n    ]\n    actual_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-vm-200\", type=\"vm\", name=\"worker_live\", provider_name=\"mock\",\n                       attributes={\"image\": \"debian\", \"ram\": \"4GB\", \"last_updated_time\": \"ts2\", \"dynamic_ip\": \"1.2.3.4\", \"tags\": {\"managed_by\": \"iac\", \"status\": \"running\"}}),\n    ]",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_compare_states_tag_value_modified",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_states_tag_value_modified():\n    iac_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-vm-300\", type=\"vm\", name=\"tagged_vm\", provider_name=\"mock\",\n                    attributes={\"tags\": {\"env\": \"staging\", \"owner\": \"team-a\"}}),\n    ]\n    actual_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-vm-300\", type=\"vm\", name=\"tagged_vm_live\", provider_name=\"mock\",\n                       attributes={\"tags\": {\"env\": \"prod\", \"owner\": \"team-a\", \"new_tag\": \"val\"}}),\n    ]\n    drifts = compare_states(iac_state, actual_state)",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_compare_states_type_mismatch_on_same_id",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_states_type_mismatch_on_same_id():\n    \"\"\" Test scenario where same ID has different resource types (should be rare, but possible if IDs are not universally unique).\"\"\"\n    iac_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-shared-01\", type=\"vm\", name=\"resource_a\", provider_name=\"mock\", attributes={})\n    ]\n    actual_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-shared-01\", type=\"disk\", name=\"resource_b_actual\", provider_name=\"mock\", attributes={})\n    ]\n    drifts = compare_states(iac_state, actual_state)\n    assert len(drifts) == 1 # Should be one MODIFIED drift indicating type mismatch",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_compare_states_empty_iac_all_unmanaged",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_states_empty_iac_all_unmanaged():\n    iac_state: List[ParsedResource] = []\n    actual_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-unmanaged-1\", type=\"vm\", name=\"vm1\", provider_name=\"mock\", attributes={}),\n        ParsedResource(id=\"id-unmanaged-2\", type=\"disk\", name=\"disk1\", provider_name=\"mock\", attributes={}),\n    ]\n    drifts = compare_states(iac_state, actual_state)\n    assert len(drifts) == 2\n    assert all(d.drift_type == DriftType.UNMANAGED_IN_ACTUAL for d in drifts)\ndef test_compare_states_empty_actual_all_missing():",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_compare_states_empty_actual_all_missing",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_states_empty_actual_all_missing():\n    iac_state: List[ParsedResource] = [\n        ParsedResource(id=\"id-missing-1\", type=\"vm\", name=\"vm_iac_1\", provider_name=\"mock\", attributes={}),\n        ParsedResource(id=\"id-missing-2\", type=\"disk\", name=\"disk_iac_1\", provider_name=\"mock\", attributes={}),\n    ]\n    actual_state: List[ParsedResource] = []\n    drifts = compare_states(iac_state, actual_state)\n    assert len(drifts) == 2\n    assert all(d.drift_type == DriftType.MISSING_IN_ACTUAL for d in drifts)\ndef test_compare_states_no_ids_in_iac_resources():",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_compare_states_no_ids_in_iac_resources",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "description": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "peekOfCode": "def test_compare_states_no_ids_in_iac_resources():\n    \"\"\" Test how it handles IaC resources that might be missing 'id' (e.g. malformed state). \"\"\"\n    iac_state: List[ParsedResource] = [\n        ParsedResource(id=None, type=\"vm\", name=\"vm_no_id\", provider_name=\"mock\", attributes={}) # type: ignore\n    ]\n    actual_state: List[ParsedResource] = [\n         ParsedResource(id=\"id-actual-1\", type=\"vm\", name=\"vm_actual_1\", provider_name=\"mock\", attributes={})\n    ]\n    # Current implementation of compare_states uses `iac_by_id = {res.id: res for res in iac_resources if res.id}`\n    # So, iac_resource without id will be skipped for MODIFIED/MISSING checks based on ID.",
        "detail": "tests.unit.test_iac_drift_detector.test_drift_engine",
        "documentation": {}
    },
    {
        "label": "test_suggest_remediation_missing_in_actual_terraform",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_remediation",
        "description": "tests.unit.test_iac_drift_detector.test_remediation",
        "peekOfCode": "def test_suggest_remediation_missing_in_actual_terraform():\n    drift = DriftInfo(\n        drift_type=DriftType.MISSING_IN_ACTUAL,\n        resource_type=\"aws_instance\",\n        resource_name=\"web_server_01\",\n        iac_resource=ParsedResource(id=\"i-expected123\", type=\"aws_instance\", name=\"web_server_01\", provider_name=\"aws\", attributes={})\n    )\n    suggestions = suggest_remediation(drift, iac_tool=\"terraform\")\n    assert len(suggestions) >= 2\n    assert f\"Resource aws_instance.web_server_01 (Expected IaC ID: i-expected123) is defined in IaC but MISSING\" in suggestions[0]",
        "detail": "tests.unit.test_iac_drift_detector.test_remediation",
        "documentation": {}
    },
    {
        "label": "test_suggest_remediation_missing_in_actual_with_module_terraform",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_remediation",
        "description": "tests.unit.test_iac_drift_detector.test_remediation",
        "peekOfCode": "def test_suggest_remediation_missing_in_actual_with_module_terraform():\n    drift = DriftInfo(\n        drift_type=DriftType.MISSING_IN_ACTUAL,\n        resource_type=\"aws_instance\",\n        resource_name=\"web_server_module\",\n        iac_resource=ParsedResource(id=\"i-expected456\", type=\"aws_instance\", name=\"web_server_module\", provider_name=\"aws\", module=\"module.my_module\", attributes={})\n    )\n    suggestions = suggest_remediation(drift, iac_tool=\"terraform\")\n    assert len(suggestions) >= 3\n    assert \"(Resource is in module: module.my_module)\" in suggestions[2]",
        "detail": "tests.unit.test_iac_drift_detector.test_remediation",
        "documentation": {}
    },
    {
        "label": "test_suggest_remediation_unmanaged_in_actual_terraform",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_remediation",
        "description": "tests.unit.test_iac_drift_detector.test_remediation",
        "peekOfCode": "def test_suggest_remediation_unmanaged_in_actual_terraform():\n    drift = DriftInfo(\n        drift_type=DriftType.UNMANAGED_IN_ACTUAL,\n        resource_type=\"aws_s3_bucket\",\n        resource_name=\"manual-bucket-007\",\n        resource_id=\"manual-bucket-007-id\",\n        actual_resource=ParsedResource(id=\"manual-bucket-007-id\", type=\"aws_s3_bucket\", name=\"manual-bucket-007\", provider_name=\"aws\", attributes={})\n    )\n    suggestions = suggest_remediation(drift, iac_tool=\"terraform\")\n    assert len(suggestions) >= 4 # Main message + 3 suggestions",
        "detail": "tests.unit.test_iac_drift_detector.test_remediation",
        "documentation": {}
    },
    {
        "label": "test_suggest_remediation_modified_terraform",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_remediation",
        "description": "tests.unit.test_iac_drift_detector.test_remediation",
        "peekOfCode": "def test_suggest_remediation_modified_terraform():\n    attr_drifts = [\n        AttributeDrift(attribute_name=\"instance_type\", iac_value=\"t2.micro\", actual_value=\"t3.small\"),\n        AttributeDrift(attribute_name=\"monitoring\", iac_value=None, actual_value=True)\n    ]\n    drift = DriftInfo(\n        drift_type=DriftType.MODIFIED,\n        resource_type=\"aws_instance\",\n        resource_name=\"app_server_main\",\n        resource_id=\"i-actual456\",",
        "detail": "tests.unit.test_iac_drift_detector.test_remediation",
        "documentation": {}
    },
    {
        "label": "test_suggest_remediation_unknown_drift_type",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_remediation",
        "description": "tests.unit.test_iac_drift_detector.test_remediation",
        "peekOfCode": "def test_suggest_remediation_unknown_drift_type():\n    # Create a dummy DriftType or mock it if Enum doesn't allow easy extension for tests\n    class MockUnknownDriftType:\n        value = \"very_unknown_drift\"\n    drift = DriftInfo(\n        drift_type=MockUnknownDriftType(), # type: ignore\n        resource_type=\"some_type\",\n        resource_name=\"some_name\",\n        resource_id=\"some_id\"\n    )",
        "detail": "tests.unit.test_iac_drift_detector.test_remediation",
        "documentation": {}
    },
    {
        "label": "test_suggest_remediation_generic_iac_tool",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_remediation",
        "description": "tests.unit.test_iac_drift_detector.test_remediation",
        "peekOfCode": "def test_suggest_remediation_generic_iac_tool():\n    drift_missing = DriftInfo(\n        drift_type=DriftType.MISSING_IN_ACTUAL,\n        resource_type=\"generic_resource\",\n        resource_name=\"test_res\",\n        iac_resource=ParsedResource(id=\"gen-id-123\", type=\"generic_resource\", name=\"test_res\", provider_name=\"any\", attributes={})\n    )\n    suggestions = suggest_remediation(drift_missing, iac_tool=\"pulumi\") # Example other tool\n    assert len(suggestions) >= 2\n    assert \"Use your IaC tool to apply the configuration and create the resource.\" in suggestions[1]",
        "detail": "tests.unit.test_iac_drift_detector.test_remediation",
        "documentation": {}
    },
    {
        "label": "sample_tfstate_content",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def sample_tfstate_content() -> dict:\n    return {\n        \"version\": 4,\n        \"terraform_version\": \"1.1.0\",\n        \"resources\": [\n            {\n                \"mode\": \"managed\",\n                \"type\": \"aws_instance\",\n                \"name\": \"web_server\",\n                \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "temp_tfstate_file",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def temp_tfstate_file(tmp_path: Path, sample_tfstate_content: dict) -> Path:\n    file_path = tmp_path / \"test.tfstate\"\n    with open(file_path, 'w') as f:\n        json.dump(sample_tfstate_content, f)\n    return file_path\n@pytest.fixture\ndef sample_tfplan_json_content() -> dict:\n    return {\n        \"format_version\": \"1.0\",\n        \"resource_changes\": [",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "sample_tfplan_json_content",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def sample_tfplan_json_content() -> dict:\n    return {\n        \"format_version\": \"1.0\",\n        \"resource_changes\": [\n            {\n                \"address\": \"aws_instance.web_server_new\",\n                \"type\": \"aws_instance\", \"name\": \"web_server_new\",\n                \"change\": {\"actions\": [\"create\"], \"after\": {\"instance_type\": \"t3.micro\"}}\n            },\n            {",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "temp_tfplan_json_file",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def temp_tfplan_json_file(tmp_path: Path, sample_tfplan_json_content: dict) -> Path:\n    file_path = tmp_path / \"test_plan.json\"\n    with open(file_path, 'w') as f:\n        json.dump(sample_tfplan_json_content, f)\n    return file_path\n# --- Tests for parse_terraform_state_file ---\ndef test_parse_tfstate_valid_file(temp_tfstate_file: Path):\n    resources = parse_terraform_state_file(str(temp_tfstate_file))\n    assert len(resources) == 3 # 2 managed resources + 1 null_resource, data source ignored\n    instance_res = next((r for r in resources if r.type == \"aws_instance\"), None)",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfstate_valid_file",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfstate_valid_file(temp_tfstate_file: Path):\n    resources = parse_terraform_state_file(str(temp_tfstate_file))\n    assert len(resources) == 3 # 2 managed resources + 1 null_resource, data source ignored\n    instance_res = next((r for r in resources if r.type == \"aws_instance\"), None)\n    assert instance_res is not None\n    assert instance_res.id == \"i-0123456789abcdef0\"\n    assert instance_res.name == \"web_server\"\n    assert instance_res.provider_name == \"aws\"\n    assert instance_res.attributes[\"instance_type\"] == \"t2.micro\"\n    assert instance_res.attributes[\"tags\"] == {\"Name\": \"web-server-prod\"}",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfstate_empty_resources",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfstate_empty_resources():\n    empty_tfstate = {\"version\": 4, \"resources\": []}\n    # Use Path object from tmp_path for writing\n    file_path = Path(Path(__file__).parent / \"empty.tfstate\") # Not ideal, should use tmp_path\n    with open(file_path, 'w') as f:\n        json.dump(empty_tfstate, f)\n    resources = parse_terraform_state_file(str(file_path))\n    assert len(resources) == 0\n    file_path.unlink() # Clean up\ndef test_parse_tfstate_no_resources_key(tmp_path: Path):",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfstate_no_resources_key",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfstate_no_resources_key(tmp_path: Path):\n    no_res_key_tfstate = {\"version\": 4} # Missing 'resources' key\n    file_path = tmp_path / \"no_res.tfstate\"\n    with open(file_path, 'w') as f:\n        json.dump(no_res_key_tfstate, f)\n    resources = parse_terraform_state_file(str(file_path))\n    assert len(resources) == 0\ndef test_parse_tfstate_file_not_found(capsys):\n    resources = parse_terraform_state_file(\"non_existent_file.tfstate\")\n    assert len(resources) == 0",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfstate_file_not_found",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfstate_file_not_found(capsys):\n    resources = parse_terraform_state_file(\"non_existent_file.tfstate\")\n    assert len(resources) == 0\n    captured = capsys.readouterr()\n    assert \"Error: Terraform state file not found\" in captured.err\ndef test_parse_tfstate_invalid_json(tmp_path: Path, capsys):\n    file_path = tmp_path / \"invalid.tfstate\"\n    file_path.write_text(\"this is not json\")\n    resources = parse_terraform_state_file(str(file_path))\n    assert len(resources) == 0",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfstate_invalid_json",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfstate_invalid_json(tmp_path: Path, capsys):\n    file_path = tmp_path / \"invalid.tfstate\"\n    file_path.write_text(\"this is not json\")\n    resources = parse_terraform_state_file(str(file_path))\n    assert len(resources) == 0\n    captured = capsys.readouterr()\n    assert \"Error: Invalid JSON\" in captured.err\n# --- Tests for parse_terraform_plan_json_file ---\ndef test_parse_tfplan_valid_file(temp_tfplan_json_file: Path):\n    changes = parse_terraform_plan_json_file(str(temp_tfplan_json_file))",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfplan_valid_file",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfplan_valid_file(temp_tfplan_json_file: Path):\n    changes = parse_terraform_plan_json_file(str(temp_tfplan_json_file))\n    assert len(changes) == 3 # Includes no-op for now\n    create_change = next((c for c in changes if c[\"change\"][\"actions\"] == [\"create\"]), None)\n    assert create_change is not None\n    assert create_change[\"address\"] == \"aws_instance.web_server_new\"\n    assert create_change[\"change\"][\"after\"][\"instance_type\"] == \"t3.micro\"\n    update_change = next((c for c in changes if c[\"change\"][\"actions\"] == [\"update\"]), None)\n    assert update_change is not None\n    assert update_change[\"address\"] == \"aws_s3_bucket.my_data_bucket\"",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfplan_file_not_found",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfplan_file_not_found(capsys):\n    changes = parse_terraform_plan_json_file(\"non_existent_plan.json\")\n    assert len(changes) == 0\n    captured = capsys.readouterr()\n    assert \"Error: Terraform plan JSON file not found\" in captured.err\ndef test_parse_tfplan_invalid_json(tmp_path: Path, capsys):\n    file_path = tmp_path / \"invalid_plan.json\"\n    file_path.write_text(\"{not_json_at_all\")\n    changes = parse_terraform_plan_json_file(str(file_path))\n    assert len(changes) == 0",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfplan_invalid_json",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfplan_invalid_json(tmp_path: Path, capsys):\n    file_path = tmp_path / \"invalid_plan.json\"\n    file_path.write_text(\"{not_json_at_all\")\n    changes = parse_terraform_plan_json_file(str(file_path))\n    assert len(changes) == 0\n    captured = capsys.readouterr()\n    assert \"Error: Invalid JSON\" in captured.err\ndef test_parse_tfplan_empty_changes(tmp_path: Path):\n    plan_content = {\"format_version\": \"1.0\", \"resource_changes\": []}\n    file_path = tmp_path / \"empty_changes_plan.json\"",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfplan_empty_changes",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfplan_empty_changes(tmp_path: Path):\n    plan_content = {\"format_version\": \"1.0\", \"resource_changes\": []}\n    file_path = tmp_path / \"empty_changes_plan.json\"\n    with open(file_path, 'w') as f:\n        json.dump(plan_content, f)\n    changes = parse_terraform_plan_json_file(str(file_path))\n    assert len(changes) == 0\ndef test_parse_tfstate_resource_missing_id_type_name(tmp_path: Path, capsys):\n    # Test case where a resource instance might be malformed (e.g., missing 'id')\n    malformed_tfstate_content = {",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tfstate_resource_missing_id_type_name",
        "kind": 2,
        "importPath": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "description": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "peekOfCode": "def test_parse_tfstate_resource_missing_id_type_name(tmp_path: Path, capsys):\n    # Test case where a resource instance might be malformed (e.g., missing 'id')\n    malformed_tfstate_content = {\n        \"version\": 4,\n        \"resources\": [\n            {\n                \"mode\": \"managed\",\n                \"type\": \"aws_instance\",\n                \"name\": \"bad_instance\",\n                \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",",
        "detail": "tests.unit.test_iac_drift_detector.test_terraform_parser",
        "documentation": {}
    },
    {
        "label": "temp_config_file",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def temp_config_file(tmp_path):\n    \"\"\"Fixture to create a temporary config file and clean it up.\"\"\"\n    file_path = tmp_path / DEFAULT_CONFIG_FILENAME\n    def _create_config(content_dict):\n        with open(file_path, 'w') as f:\n            yaml.dump(content_dict, f)\n        return file_path\n    yield _create_config\n    # No explicit cleanup needed for tmp_path, pytest handles it\ndef test_load_config_default_values():",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_config_default_values",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_load_config_default_values():\n    \"\"\"Test loading config when no file exists, should return defaults.\"\"\"\n    config = load_config(config_path=\"non_existent_file.yml\") # Should trigger default loading path if not found\n    assert isinstance(config, PolicyConfig)\n    assert config.branch_naming.enabled is True\n    assert config.branch_naming.pattern.pattern == \"^(feature|fix|chore|docs|style|refactor|test)/[a-zA-Z0-9_.-]+$\"\n    assert config.commit_messages.enabled is True\n    assert config.file_size.max_bytes == 1048576\ndef test_load_config_from_file(temp_config_file):\n    \"\"\"Test loading a valid configuration from a YAML file.\"\"\"",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_config_from_file",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_load_config_from_file(temp_config_file):\n    \"\"\"Test loading a valid configuration from a YAML file.\"\"\"\n    custom_config_data = {\n        \"branch_naming\": {\"pattern\": \"^custom/.+$\", \"enabled\": True},\n        \"commit_messages\": {\n            \"conventional_commit\": {\"types\": [\"task\", \"bugfix\"]},\n            \"require_issue_number\": {\"enabled\": True, \"pattern\": \"TASK-\\\\d+\"},\n            \"enabled\": True\n        },\n        \"disallowed_patterns\": {",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_config_empty_file",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_load_config_empty_file(temp_config_file):\n    \"\"\"Test loading an empty YAML file, should use defaults.\"\"\"\n    config_file_path = temp_config_file({}) # Empty dict makes an empty YAML file\n    original_cwd = os.getcwd()\n    os.chdir(config_file_path.parent)\n    try:\n        config = load_config()\n    finally:\n        os.chdir(original_cwd)\n    assert isinstance(config, PolicyConfig)",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_config_partial_config",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_load_config_partial_config(temp_config_file):\n    \"\"\"Test loading a file with only some sections defined.\"\"\"\n    partial_data = {\n        \"branch_naming\": {\"enabled\": False}\n    }\n    config_file_path = temp_config_file(partial_data)\n    original_cwd = os.getcwd()\n    os.chdir(config_file_path.parent)\n    try:\n        config = load_config()",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_config_invalid_yaml",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_load_config_invalid_yaml(temp_config_file):\n    \"\"\"Test loading a file with invalid YAML content.\"\"\"\n    file_path = temp_config_file(None) # Create empty file first\n    with open(file_path, 'w') as f:\n        f.write(\"branch_naming: {pattern: 'foo', enabled: true\") # Missing closing }\n    original_cwd = os.getcwd()\n    os.chdir(file_path.parent)\n    with pytest.raises(ValueError, match=\"Error parsing YAML configuration file\"):\n        try:\n            load_config()",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_load_config_validation_error",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_load_config_validation_error(temp_config_file):\n    \"\"\"Test loading a file with valid YAML but data that fails Pydantic validation.\"\"\"\n    invalid_data = {\n        \"file_size\": {\"max_bytes\": \"not-an-integer\"}\n    }\n    config_file_path = temp_config_file(invalid_data)\n    original_cwd = os.getcwd()\n    os.chdir(config_file_path.parent)\n    with pytest.raises(ValueError, match=\"Configuration validation error\"):\n        try:",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_regex_compilation_in_models",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_regex_compilation_in_models():\n    \"\"\"Test that regex patterns are compiled correctly in Pydantic models.\"\"\"\n    bn_policy = BranchNamingPolicy(pattern=\"^test/.+$\")\n    assert isinstance(bn_policy.pattern, re.Pattern)\n    assert bn_policy.pattern.pattern == \"^test/.+$\"\n    ri_policy = RequireIssueNumberPolicy(pattern=\"^T-\\\\d+$\", enabled=True)\n    assert isinstance(ri_policy.pattern, re.Pattern)\n    assert ri_policy.pattern.pattern == \"^T-\\\\d+$\"\n    dp_item = DisallowedPatternItem(pattern=\"secret\")\n    assert isinstance(dp_item.pattern, re.Pattern)",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_invalid_regex_pattern_in_models",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_invalid_regex_pattern_in_models():\n    \"\"\"Test that invalid regex patterns raise ValueError during model instantiation.\"\"\"\n    with pytest.raises(ValidationError): # Pydantic wraps it in ValidationError\n        BranchNamingPolicy(pattern=\"*invalidregex\")\n    with pytest.raises(ValidationError):\n        RequireIssueNumberPolicy(pattern=\"[\", enabled=True)\n    with pytest.raises(ValidationError):\n        DisallowedPatternItem(pattern=\"(?<invalid)\")\ndef test_default_config_file_search_logic(tmp_path):\n    \"\"\"Test the search logic for the default config file.\"\"\"",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_default_config_file_search_logic",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_default_config_file_search_logic(tmp_path):\n    \"\"\"Test the search logic for the default config file.\"\"\"\n    # Setup: create a .pr-policy.yml in a subdirectory\n    project_root = tmp_path\n    sub_dir = project_root / \"subdir1\" / \"subdir2\"\n    sub_dir.mkdir(parents=True)\n    config_content = {\"branch_naming\": {\"pattern\": \"^search_logic_test/.+$\"}}\n    with open(sub_dir / DEFAULT_CONFIG_FILENAME, 'w') as f:\n        yaml.dump(config_content, f)\n    # Test 1: Run from a deeper directory, should find the file in parent",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_branch_naming_policy_defaults",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_branch_naming_policy_defaults():\n    policy = BranchNamingPolicy()\n    assert policy.enabled is True\n    assert policy.pattern.pattern == \"^(feature|fix|chore|docs|style|refactor|test)/[a-zA-Z0-9_.-]+$\"\ndef test_conventional_commit_policy_defaults():\n    policy = ConventionalCommitPolicy()\n    assert policy.enabled is True\n    assert policy.types == [\"feat\", \"fix\", \"docs\", \"style\", \"refactor\", \"test\", \"chore\"]\ndef test_require_issue_number_policy_defaults():\n    policy = RequireIssueNumberPolicy()",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_conventional_commit_policy_defaults",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_conventional_commit_policy_defaults():\n    policy = ConventionalCommitPolicy()\n    assert policy.enabled is True\n    assert policy.types == [\"feat\", \"fix\", \"docs\", \"style\", \"refactor\", \"test\", \"chore\"]\ndef test_require_issue_number_policy_defaults():\n    policy = RequireIssueNumberPolicy()\n    assert policy.enabled is False\n    assert policy.pattern.pattern == \"\\\\[[A-Z]+-[0-9]+\\\\]\"\n    assert policy.in_commit_body is True\ndef test_disallowed_patterns_policy_defaults():",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_require_issue_number_policy_defaults",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_require_issue_number_policy_defaults():\n    policy = RequireIssueNumberPolicy()\n    assert policy.enabled is False\n    assert policy.pattern.pattern == \"\\\\[[A-Z]+-[0-9]+\\\\]\"\n    assert policy.in_commit_body is True\ndef test_disallowed_patterns_policy_defaults():\n    policy = DisallowedPatternsPolicy()\n    assert policy.enabled is True\n    assert policy.patterns == []\ndef test_file_size_policy_defaults():",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_disallowed_patterns_policy_defaults",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_disallowed_patterns_policy_defaults():\n    policy = DisallowedPatternsPolicy()\n    assert policy.enabled is True\n    assert policy.patterns == []\ndef test_file_size_policy_defaults():\n    policy = FileSizePolicy()\n    assert policy.enabled is True\n    assert policy.max_bytes == 1048576\n    assert policy.ignore_extensions == []\n    assert policy.ignore_paths == []",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_file_size_policy_defaults",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_config",
        "description": "tests.unit.test_pr_reviewer.test_config",
        "peekOfCode": "def test_file_size_policy_defaults():\n    policy = FileSizePolicy()\n    assert policy.enabled is True\n    assert policy.max_bytes == 1048576\n    assert policy.ignore_extensions == []\n    assert policy.ignore_paths == []",
        "detail": "tests.unit.test_pr_reviewer.test_config",
        "documentation": {}
    },
    {
        "label": "test_check_branch_name_policy_valid",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_branch_name_policy_valid():\n    policy = BranchNamingPolicy(pattern=\"^(feat|fix)/[a-z0-9-]+$\", enabled=True)\n    assert branch_policies.check_branch_name_policy(\"feat/new-stuff-123\", policy) == []\ndef test_check_branch_name_policy_invalid():\n    pattern_str = \"^(feat|fix)/[a-z0-9-]+$\"\n    policy = BranchNamingPolicy(pattern=pattern_str, enabled=True)\n    violations = branch_policies.check_branch_name_policy(\"Feature/InvalidName\", policy)\n    assert len(violations) == 1\n    assert f\"does not match the required pattern: '{pattern_str}'\" in violations[0]\ndef test_check_branch_name_policy_disabled():",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_branch_name_policy_invalid",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_branch_name_policy_invalid():\n    pattern_str = \"^(feat|fix)/[a-z0-9-]+$\"\n    policy = BranchNamingPolicy(pattern=pattern_str, enabled=True)\n    violations = branch_policies.check_branch_name_policy(\"Feature/InvalidName\", policy)\n    assert len(violations) == 1\n    assert f\"does not match the required pattern: '{pattern_str}'\" in violations[0]\ndef test_check_branch_name_policy_disabled():\n    policy = BranchNamingPolicy(pattern=\"^valid/.+$\", enabled=False)\n    assert branch_policies.check_branch_name_policy(\"anything/goes\", policy) == []\ndef test_check_branch_name_policy_detached_head():",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_branch_name_policy_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_branch_name_policy_disabled():\n    policy = BranchNamingPolicy(pattern=\"^valid/.+$\", enabled=False)\n    assert branch_policies.check_branch_name_policy(\"anything/goes\", policy) == []\ndef test_check_branch_name_policy_detached_head():\n    policy = BranchNamingPolicy(pattern=\"^valid/.+$\", enabled=True)\n    violations = branch_policies.check_branch_name_policy(None, policy)\n    assert len(violations) == 1\n    assert \"Branch name could not be determined\" in violations[0]\n# --- Tests for commit policies ---\n@pytest.mark.parametrize(\"subject, types, is_valid\", [",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_branch_name_policy_detached_head",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_branch_name_policy_detached_head():\n    policy = BranchNamingPolicy(pattern=\"^valid/.+$\", enabled=True)\n    violations = branch_policies.check_branch_name_policy(None, policy)\n    assert len(violations) == 1\n    assert \"Branch name could not be determined\" in violations[0]\n# --- Tests for commit policies ---\n@pytest.mark.parametrize(\"subject, types, is_valid\", [\n    (\"feat: add new feature\", [\"feat\", \"fix\"], True),\n    (\"fix(scope): resolve bug\", [\"feat\", \"fix\"], True),\n    (\"docs!: update README with breaking change\", [\"docs\", \"feat\"], True),",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_conventional_commit_format",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_conventional_commit_format(subject, types, is_valid):\n    policy = ConventionalCommitPolicy(enabled=True, types=types)\n    violations = commit_policies.check_conventional_commit_format(subject, \"sha123\", policy)\n    if is_valid:\n        assert not violations, f\"Expected no violations for '{subject}' with types {types}\"\n    else:\n        assert violations, f\"Expected violations for '{subject}' with types {types}\"\ndef test_check_conventional_commit_format_disabled():\n    policy = ConventionalCommitPolicy(enabled=False, types=[\"feat\"])\n    violations = commit_policies.check_conventional_commit_format(\"anything goes\", \"sha123\", policy)",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_conventional_commit_format_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_conventional_commit_format_disabled():\n    policy = ConventionalCommitPolicy(enabled=False, types=[\"feat\"])\n    violations = commit_policies.check_conventional_commit_format(\"anything goes\", \"sha123\", policy)\n    assert not violations\n@pytest.mark.parametrize(\"body, pattern_str, pr_title, pr_body, in_commit_body, expected_violations_count\", [\n    (\"Fixes TICKET-123\", r\"TICKET-\\d+\", None, None, True, 0),\n    (\"Related to task [PROJ-001]\", r\"\\[PROJ-\\d+\\]\", None, None, True, 0),\n    (\"No ticket here.\", r\"TICKET-\\d+\", None, None, True, 1),\n    (\"Body has TICKET-123\", r\"TICKET-\\d+\", None, None, False, 0), # Policy check for body disabled\n    # Future tests for PR title/body would go here",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_commit_for_issue_number",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_commit_for_issue_number(body, pattern_str, pr_title, pr_body, in_commit_body, expected_violations_count):\n    policy = RequireIssueNumberPolicy(pattern=pattern_str, in_commit_body=in_commit_body, enabled=True)\n    violations = commit_policies.check_commit_for_issue_number(body, pr_title, pr_body, \"sha123\", policy)\n    assert len(violations) == expected_violations_count\ndef test_check_commit_for_issue_number_disabled():\n    policy = RequireIssueNumberPolicy(pattern=r\"TICKET-\\d+\", enabled=False)\n    violations = commit_policies.check_commit_for_issue_number(\"No ticket needed\", None, None, \"sha123\", policy)\n    assert not violations\ndef test_check_commit_message_policies_orchestration():\n    commit_details = {",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_commit_for_issue_number_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_commit_for_issue_number_disabled():\n    policy = RequireIssueNumberPolicy(pattern=r\"TICKET-\\d+\", enabled=False)\n    violations = commit_policies.check_commit_for_issue_number(\"No ticket needed\", None, None, \"sha123\", policy)\n    assert not violations\ndef test_check_commit_message_policies_orchestration():\n    commit_details = {\n        \"sha\": \"testsha\",\n        \"message_subject\": \"badtype: this is a test\",\n        \"message_body\": \"This commit has no ticket reference.\"\n    }",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_commit_message_policies_orchestration",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_commit_message_policies_orchestration():\n    commit_details = {\n        \"sha\": \"testsha\",\n        \"message_subject\": \"badtype: this is a test\",\n        \"message_body\": \"This commit has no ticket reference.\"\n    }\n    policy = CommitMessagePolicy(\n        conventional_commit=ConventionalCommitPolicy(enabled=True, types=[\"feat\", \"fix\"]),\n        require_issue_number=RequireIssueNumberPolicy(pattern=r\"TICKET-\\d+\", in_commit_body=True, enabled=True),\n        enabled=True",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "mock_get_file_content",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def mock_get_file_content(filepath: str) -> Optional[AnyStr]:\n    return mock_file_contents.get(filepath)\n@pytest.mark.parametrize(\"filepath, patterns_config, expected_violations_count, expected_messages_contain\", [\n    (\"secrets.py\", [DisallowedPatternItem(pattern=\"API_KEY\\\\s*=\", enabled=True)], 1, [\"API_KEY\"]),\n    (\"secrets.py\", [DisallowedPatternItem(pattern=\"PASSWORD\\\\s*=\", enabled=True)], 1, [\"PASSWORD\"]),\n    (\"secrets.py\", [\n        DisallowedPatternItem(pattern=\"API_KEY\\\\s*=\", enabled=True),\n        DisallowedPatternItem(pattern=\"PASSWORD\\\\s*=\", enabled=True)\n    ], 2, [\"API_KEY\", \"PASSWORD\"]),\n    (\"clean.txt\", [DisallowedPatternItem(pattern=\"SECRET\", enabled=True)], 0, []),",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_content_disallowed_patterns",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_content_disallowed_patterns(filepath, patterns_config, expected_violations_count, expected_messages_contain):\n    policy = DisallowedPatternsPolicy(patterns=patterns_config, enabled=True)\n    violations = file_policies.check_content_disallowed_patterns(filepath, mock_get_file_content, policy)\n    assert len(violations) == expected_violations_count\n    for msg_part in expected_messages_contain:\n        assert any(msg_part in v for v in violations), f\"Expected part '{msg_part}' not in violations: {violations}\"\ndef test_check_content_disallowed_patterns_disabled():\n    policy = DisallowedPatternsPolicy(patterns=[DisallowedPatternItem(pattern=\"SECRET\", enabled=True)], enabled=False)\n    violations = file_policies.check_content_disallowed_patterns(\"secrets.py\", mock_get_file_content, policy)\n    assert not violations",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_content_disallowed_patterns_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_content_disallowed_patterns_disabled():\n    policy = DisallowedPatternsPolicy(patterns=[DisallowedPatternItem(pattern=\"SECRET\", enabled=True)], enabled=False)\n    violations = file_policies.check_content_disallowed_patterns(\"secrets.py\", mock_get_file_content, policy)\n    assert not violations\n# Mock file size getter for size tests\nmock_file_sizes = {\n    \"small.txt\": 100,\n    \"large.exe\": 2000000,\n    \"ignored.log\": 5000000,\n    \"vendor/big_lib.js\": 3000000,",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "mock_get_file_size",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def mock_get_file_size(filepath: str) -> Optional[int]:\n    return mock_file_sizes.get(filepath)\n@pytest.mark.parametrize(\"filepath, max_bytes, ignore_ext, ignore_paths, expected_violations_count\", [\n    (\"small.txt\", 1000, [], [], 0),\n    (\"large.exe\", 1000000, [], [], 1), # Exceeds 1MB\n    (\"ignored.log\", 100, [\".log\"], [], 0), # Ignored by extension\n    (\"vendor/big_lib.js\", 1000, [], [\"vendor/*\"], 0), # Ignored by path\n    (\"docs/image.png\", 1000, [], [], 1), # Exceeds 1000 bytes (not 1KB)\n    (\"not_found.txt\", 1000, [], [], 0), # Size unknown, skipped\n])",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_file_size_policy",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_file_size_policy(filepath, max_bytes, ignore_ext, ignore_paths, expected_violations_count):\n    policy = FileSizePolicy(max_bytes=max_bytes, ignore_extensions=ignore_ext, ignore_paths=ignore_paths, enabled=True)\n    violations = file_policies.check_file_size_policy(filepath, mock_get_file_size, policy)\n    assert len(violations) == expected_violations_count\ndef test_check_file_size_policy_disabled():\n    policy = FileSizePolicy(max_bytes=10, enabled=False)\n    violations = file_policies.check_file_size_policy(\"large.exe\", mock_get_file_size, policy)\n    assert not violations",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_check_file_size_policy_disabled",
        "kind": 2,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "def test_check_file_size_policy_disabled():\n    policy = FileSizePolicy(max_bytes=10, enabled=False)\n    violations = file_policies.check_file_size_policy(\"large.exe\", mock_get_file_size, policy)\n    assert not violations",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "mock_file_contents",
        "kind": 5,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "mock_file_contents = {\n    \"secrets.py\": \"API_KEY = '12345'\\nPASSWORD = \\\"secret\\\"\\nOTHER_VAR='ok'\",\n    \"clean.txt\": \"This file is clean.\",\n    \"binary.data\": b\"\\x00\\x01\\x02SECRET_KEY\", # Will be skipped by content check\n    \"utf8_error.txt\": b\"Invalid \\xff UTF-8\" # Will be skipped\n}\ndef mock_get_file_content(filepath: str) -> Optional[AnyStr]:\n    return mock_file_contents.get(filepath)\n@pytest.mark.parametrize(\"filepath, patterns_config, expected_violations_count, expected_messages_contain\", [\n    (\"secrets.py\", [DisallowedPatternItem(pattern=\"API_KEY\\\\s*=\", enabled=True)], 1, [\"API_KEY\"]),",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "mock_file_sizes",
        "kind": 5,
        "importPath": "tests.unit.test_pr_reviewer.test_policies",
        "description": "tests.unit.test_pr_reviewer.test_policies",
        "peekOfCode": "mock_file_sizes = {\n    \"small.txt\": 100,\n    \"large.exe\": 2000000,\n    \"ignored.log\": 5000000,\n    \"vendor/big_lib.js\": 3000000,\n    \"docs/image.png\": 1024, # 1KB\n    \"not_found.txt\": None\n}\ndef mock_get_file_size(filepath: str) -> Optional[int]:\n    return mock_file_sizes.get(filepath)",
        "detail": "tests.unit.test_pr_reviewer.test_policies",
        "documentation": {}
    },
    {
        "label": "test_health_check",
        "kind": 2,
        "importPath": "tests.unit.test_server",
        "description": "tests.unit.test_server",
        "peekOfCode": "def test_health_check():\n    \"\"\"\n    Test the /health endpoint.\n    It should return a 200 OK status and a JSON response with {\"status\": \"ok\"}.\n    \"\"\"\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    assert response.json() == {\"status\": \"ok\"}\ndef test_create_context_success():\n    \"\"\"",
        "detail": "tests.unit.test_server",
        "documentation": {}
    },
    {
        "label": "test_create_context_success",
        "kind": 2,
        "importPath": "tests.unit.test_server",
        "description": "tests.unit.test_server",
        "peekOfCode": "def test_create_context_success():\n    \"\"\"\n    Test successful context creation.\n    \"\"\"\n    context_id = \"test_context_01\"\n    response = client.post(\"/v1/contexts\", json={\"context_id\": context_id})\n    assert response.status_code == 201\n    assert response.json() == {\"message\": \"Context created successfully\", \"context_id\": context_id}\n    # Verify it's in the store (optional, depends on how much you want to test internal state)\n    # This requires access to CONTEXT_STORE or a way to inspect it.",
        "detail": "tests.unit.test_server",
        "documentation": {}
    },
    {
        "label": "test_create_context_conflict",
        "kind": 2,
        "importPath": "tests.unit.test_server",
        "description": "tests.unit.test_server",
        "peekOfCode": "def test_create_context_conflict():\n    \"\"\"\n    Test creating a context that already exists.\n    \"\"\"\n    context_id = \"test_context_conflict\"\n    # Create it once\n    client.post(\"/v1/contexts\", json={\"context_id\": context_id})\n    # Try to create it again\n    response = client.post(\"/v1/contexts\", json={\"context_id\": context_id})\n    assert response.status_code == 409",
        "detail": "tests.unit.test_server",
        "documentation": {}
    },
    {
        "label": "test_get_context_not_found",
        "kind": 2,
        "importPath": "tests.unit.test_server",
        "description": "tests.unit.test_server",
        "peekOfCode": "def test_get_context_not_found():\n    \"\"\"\n    Test retrieving a context that does not exist.\n    \"\"\"\n    response = client.get(\"/v1/contexts/non_existent_context\")\n    assert response.status_code == 404\n    assert response.json() == {\"detail\": \"Context not found\"}\n# Clean up contexts created during tests to ensure test isolation if needed\n# For simple in-memory store, this might not be strictly necessary if TestClient re-initializes state,\n# but good practice for more complex scenarios.",
        "detail": "tests.unit.test_server",
        "documentation": {}
    },
    {
        "label": "clear_context_store_after_each_test",
        "kind": 2,
        "importPath": "tests.unit.test_server",
        "description": "tests.unit.test_server",
        "peekOfCode": "def clear_context_store_after_each_test():\n    \"\"\"\n    Fixture to clear the CONTEXT_STORE after each test that might modify it.\n    \"\"\"\n    # Setup:\n    # Could backup CONTEXT_STORE here if needed\n    yield # This is where the test runs\n    # Teardown: Clear the CONTEXT_STORE\n    from src.mcp_server.main import CONTEXT_STORE\n    CONTEXT_STORE.clear()",
        "detail": "tests.unit.test_server",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "tests.unit.test_server",
        "description": "tests.unit.test_server",
        "peekOfCode": "client = TestClient(app)\ndef test_health_check():\n    \"\"\"\n    Test the /health endpoint.\n    It should return a 200 OK status and a JSON response with {\"status\": \"ok\"}.\n    \"\"\"\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    assert response.json() == {\"status\": \"ok\"}\ndef test_create_context_success():",
        "detail": "tests.unit.test_server",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def main():\n    print(\"Hello from app!\")\nif __name__ == \"__main__\":\n    main()",
        "detail": "main",
        "documentation": {}
    }
]